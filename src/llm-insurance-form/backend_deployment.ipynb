{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zx3Qmwu78Tw_"
   },
   "source": [
    "# Download packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0uVUSlmdWfX",
    "outputId": "8660f0fb-a0fd-4eef-88f9-c1dbd09da57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "0% [Working]\r\n",
      "            \r\n",
      "Hit:1 https://cli.github.com/packages stable InRelease\n",
      "\r\n",
      "0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\r\n",
      "                                                                               \r\n",
      "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,432 kB]\n",
      "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,969 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,856 kB]\n",
      "19% [15 Packages 12.8 kB/3,856 kB 0%] [14 Packages 255 kB/5,969 kB 4%] [12 Pack"
     ]
    }
   ],
   "source": [
    "!apt-get update -y\n",
    "!apt-get install -y curl tesseract-ocr libopenjp2-7 libtiff5 ghostscript\n",
    "\n",
    "# Python dependencies\n",
    "!pip install flask flask_cors pyngrok requests werkzeug typing\n",
    "!pip install fitz ocrmypdf PyMuPDF\n",
    "!pip install ocrmypdf PyMuPDF==1.24.10\n",
    "!pip install sentence-transformers pymilvus[model] pymilvus[milvus_lite] nltk\n",
    "\n",
    "# Lock image libraries\n",
    "!pip install --no-deps --force-reinstall \"Pillow==10.3.0\" \"img2pdf==0.4.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrNYJMvPyWQt"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxyTwFZ8wY-W"
   },
   "outputs": [],
   "source": [
    "# Ollama startup\n",
    "\n",
    "# Install Ollama\n",
    "!command -v ollama >/dev/null 2>&1 || (curl -fsSL https://ollama.com/install.sh | sh)\n",
    "\n",
    "# Start Ollama server in background\n",
    "!ollama serve > /dev/null 2>&1 &\n",
    "\n",
    "# Pull model \n",
    "!ollama pull phi4\n",
    "\n",
    "# Verify server is alive\n",
    "!curl http://localhost:11434/api/tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFp-paT42XeW"
   },
   "source": [
    "# Medical Files Processing (Pre-processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXTBbQW8xFUV"
   },
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfOv9MRH2bVL"
   },
   "outputs": [],
   "source": [
    "import os, re, io, json, shutil, time, fitz, ocrmypdf, yaml\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "try:\n",
    "    from multiprocessing import Pool, cpu_count\n",
    "    _MP_AVAILABLE = True\n",
    "except Exception:\n",
    "    _MP_AVAILABLE = False\n",
    "\n",
    "\n",
    "# Embedded Config (from original YAML)\n",
    "CONFIG = yaml.safe_load(\"\"\"\n",
    "lab_results_config:\n",
    "  test_detection:\n",
    "    name_stopwords: [\"Final\", \"Report Link\"]\n",
    "  cleanup_words: [\"Final\", \"Updated\"]\n",
    "\n",
    "medical_records_config:\n",
    "  pdf_cleaning:\n",
    "    hospital_patterns:\n",
    "      - \"National Cancer Centre\"\n",
    "      - \"Singapore General Hospital\"\n",
    "      - \".*Hospital.*\"\n",
    "    footer_patterns:\n",
    "      - \"Requested by:\"\n",
    "      - \"computer generated\"\n",
    "      - \"printed from\"\n",
    "      - \"page\"\n",
    "  section_headers:\n",
    "    ignored: [\"NUR\", \"PHA\", \"CTR\", \"DISTRESS SCREENING NOTE\"]\n",
    "    subsections:\n",
    "      - \"History, Examination and Investigations\"\n",
    "      - \"Cancer Risk\"\n",
    "      - \"Investigations\"\n",
    "      - \"IMPRESSION\"\n",
    "      - \"Clinical and Treatment Summary\"\n",
    "      - \"DIAGNOSIS SUMMARY\"\n",
    "      - \"MANAGEMENT FOR THIS VISIT\"\n",
    "      - \"PATIENT STATUS\"\n",
    "  normalization:\n",
    "    month_map:\n",
    "      Jan: \"01\"\n",
    "      Feb: \"02\"\n",
    "      Mar: \"03\"\n",
    "      Apr: \"04\"\n",
    "      May: \"05\"\n",
    "      Jun: \"06\"\n",
    "      Jul: \"07\"\n",
    "      Aug: \"08\"\n",
    "      Sep: \"09\"\n",
    "      Oct: \"10\"\n",
    "      Nov: \"11\"\n",
    "      Dec: \"12\"\n",
    "    abbreviation_map:\n",
    "      ANC: \"Absolute Neutrophil Count\"\n",
    "      URTI: \"Upper Respiratory Tract Infection\"\n",
    "      CRP: \"C-Reactive Protein\"\n",
    "      FBC: \"Full Blood Count\"\n",
    "      Hb: \"Haemoglobin\"\n",
    "      Plt: \"Platelets\"\n",
    "      Het: \"Haematocrit\"\n",
    "      PR: \"progesterone receptor\"\n",
    "      ER: \"estrogen receptor\"\n",
    "      NAD: \"no abnormality detected\"\n",
    "      O/E: \"On examination:\"\n",
    "      Neoadjuvant: \"pre-operative\"\n",
    "      Pt: \"Patient\"\n",
    "      s/b: \"seen by\"\n",
    "      c/o: \"complaints of\"\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9GVF0nJxM3w"
   },
   "source": [
    "## Lab Results Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dVk2i8axNOO"
   },
   "outputs": [],
   "source": [
    "class LabResultParser:\n",
    "    _REGEX_HEADER_PATTERNS = [\n",
    "        r\"^\\s*(?:National Cancer Centre|Patient Results|Singapore General Hospital|.*Hospital.*)\\s*$\",\n",
    "        r\"^\\s*All results performed dates from.*$\",\n",
    "        r\"^\\s*Requested By:.*?\\d{2}/\\d{2}/\\d{4}\\s+\\d{2}:\\d{2}\\s*$\",\n",
    "        r\"^\\s*Current Location:.*$\",\n",
    "    ]\n",
    "    _REGEX_FOOTER_PATTERNS = [\n",
    "        r\"^\\s*this is a computer generated report.*$\",\n",
    "        r\"^\\s*printed from:.*$\",\n",
    "        r\"^\\s*page:\\s*\\d+\\s*$\",\n",
    "        r\"^\\s*requested by:.*page\\s*\\d+\\s*of\\s*\\d+.*$\",\n",
    "        r\"End of Report\\s*$\",\n",
    "    ]\n",
    "    _REGEX_DATETIME_PATTERN = r\"(\\d{1,2}-[A-Za-z]{3}-\\d{4}\\s+\\d{2}:\\d{2})\\s*\"\n",
    "    _REGEX_DATE_PATTERN = r\"(\\d{1,2}-[A-Za-z]{3}-\\d{4})\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.config = CONFIG[\"lab_results_config\"]\n",
    "        self._compiled_header_patterns = [re.compile(p, re.IGNORECASE | re.MULTILINE) for p in self._REGEX_HEADER_PATTERNS]\n",
    "        self._compiled_footer_patterns = [re.compile(p, re.IGNORECASE | re.MULTILINE) for p in self._REGEX_FOOTER_PATTERNS]\n",
    "\n",
    "    def extract_text_no_header_footer(self, pdf_path: Union[str, Path]) -> str:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        pages = []\n",
    "        for page in doc:\n",
    "            text = page.get_text(\"text\")\n",
    "            for pat in self._compiled_header_patterns: text = pat.sub(\"\", text)\n",
    "            for pat in self._compiled_footer_patterns: text = pat.sub(\"\", text)\n",
    "            text = re.sub(r\"[^\\x00-\\x7F\\n\\r]+\", \"\", text)\n",
    "            text = re.sub(r\"\\n\\s*\\n\\s*\\n+\", \"\\n\\n\", text)\n",
    "            text = re.sub(r\" {2,}\", \" \", text)\n",
    "            pages.append(text.strip())\n",
    "        return \"\\n\\n\".join(pages)\n",
    "\n",
    "    def clean_test_name(self, raw_header: str) -> str:\n",
    "        stopwords = \"|\".join(self.config[\"test_detection\"][\"name_stopwords\"])\n",
    "        m = re.match(rf\"(.*?)(?:\\s+(?:{stopwords})|$)\", raw_header, re.IGNORECASE)\n",
    "        name = m.group(1).strip() if m and m.group(1) else raw_header\n",
    "        return re.sub(r\"\\s+\", \" \", name).strip()\n",
    "\n",
    "    def parse_all_tests(self, text: str) -> List[Dict[str, str]]:\n",
    "        datetime_pattern = re.compile(self._REGEX_DATETIME_PATTERN, re.DOTALL)\n",
    "        date_pattern = re.compile(self._REGEX_DATE_PATTERN)\n",
    "        parts = datetime_pattern.split(text)\n",
    "        tests = []\n",
    "        for i in range(1, len(parts), 2):\n",
    "            stamp = parts[i].strip()\n",
    "            body = parts[i + 1].strip() if i + 1 < len(parts) else \"\"\n",
    "            date = date_pattern.match(stamp).group(1) if date_pattern.match(stamp) else \"UNKNOWN\"\n",
    "            test_header = body.split(\"\\n\", 1)[0].strip()\n",
    "            test_name = self.clean_test_name(test_header)\n",
    "            if test_name and body:\n",
    "                tests.append({\"date\": date, \"test_name\": test_name, \"raw_details\": body})\n",
    "\n",
    "        aggregated = []\n",
    "        current = tests[0] if tests else None\n",
    "        def key(d,n): return d + \"-\" + re.sub(r\"[,\\s\\.]\", \"\", n).lower()\n",
    "        for nxt in tests[1:]:\n",
    "            if current and key(current[\"date\"], current[\"test_name\"]) == key(nxt[\"date\"], nxt[\"test_name\"]):\n",
    "                current[\"raw_details\"] += \"\\n\\n\" + nxt[\"raw_details\"]\n",
    "            else:\n",
    "                if current: aggregated.append(current)\n",
    "                current = nxt\n",
    "        if current: aggregated.append(current)\n",
    "        return aggregated\n",
    "\n",
    "    def normalize_test_details(self, text: str) -> str:\n",
    "        cleanup_words = \"|\".join(self.config[\"cleanup_words\"])\n",
    "        text = re.sub(rf\"({cleanup_words})\\s*\", \" \", text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r\"\\s*\\n\\s*\", \"\\n\", text)\n",
    "        return re.sub(r\" {2,}\", \" \", text).strip()\n",
    "\n",
    "    def build_timeline(self, pdf_path: Union[str, Path]) -> Dict[str, List[Dict]]:\n",
    "        raw = self.extract_text_no_header_footer(pdf_path)\n",
    "        tests = self.parse_all_tests(raw)\n",
    "        grouped = defaultdict(dict)\n",
    "        for t in tests:\n",
    "            grouped[t[\"date\"]][t[\"test_name\"]] = self.normalize_test_details(t[\"raw_details\"])\n",
    "        return {d: [{\"lab results\": v}] for d, v in grouped.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqFKmuRLxVrn"
   },
   "source": [
    "## Medical Records Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVnNx409xV30"
   },
   "outputs": [],
   "source": [
    "class MedicalRecordsParser:\n",
    "    _REGEX_DMO_HEADER = (\n",
    "        r\".{0,10}?DMO\\s*(Consult|Correspondence|Pre[- ]?clerk\\s*Consult|\"\n",
    "        r\"Inpatient\\s*(?:Admission\\s*Note|Daily\\s*Ward\\s*Round(?:\\s*V\\d+)?)|\"\n",
    "        r\"Correspondence\\s*Note).{0,50}?\\[Charted\\s*Location:\"\n",
    "    )\n",
    "    _REGEX_AUTHORED_DATE = r\"Authored:\\s*(\\d{1,2}-[A-Za-z]{3}-\\d{4})\"\n",
    "    _REGEX_LAST_UPDATED_DOCTOR = r\"Last\\s*Updated:.*?by\\s+([A-Za-z\\s\\-]+)\\s*\\(Doctor\\)\"\n",
    "    _REGEX_JUNK_LINE = r\"([^\\w\\s])\\1{8,}\"\n",
    "    _REGEX_DATE_NORMALIZE = r\"(\\d{1,2})-([A-Za-z]{3})-(\\d{4})\"\n",
    "    _REGEX_NON_ASCII = r\"[^\\x00-\\x7F]+\"\n",
    "    _REGEX_ALLERGIES = r\"Allergies[: ]+(.*)\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.config = CONFIG[\"medical_records_config\"]\n",
    "        self.DMO_HEADER_REGEX = re.compile(self._REGEX_DMO_HEADER, re.IGNORECASE | re.DOTALL)\n",
    "        self._authored_date_re = re.compile(self._REGEX_AUTHORED_DATE, re.IGNORECASE)\n",
    "        self._last_updated_re = re.compile(self._REGEX_LAST_UPDATED_DOCTOR, re.IGNORECASE)\n",
    "        self._junk_line_re = re.compile(self._REGEX_JUNK_LINE)\n",
    "        self._date_norm = re.compile(self._REGEX_DATE_NORMALIZE)\n",
    "        self._non_ascii = re.compile(self._REGEX_NON_ASCII)\n",
    "        self._allergies_re = re.compile(self._REGEX_ALLERGIES, re.IGNORECASE)\n",
    "        self.hospitals = self.config[\"pdf_cleaning\"][\"hospital_patterns\"]\n",
    "        self.footers = self.config[\"pdf_cleaning\"][\"footer_patterns\"]\n",
    "        self.subsections = self.config[\"section_headers\"][\"subsections\"]\n",
    "        self.month_map = self.config[\"normalization\"][\"month_map\"]\n",
    "        self.abbr_map = self.config[\"normalization\"][\"abbreviation_map\"]\n",
    "\n",
    "    def extract_text_no_header_footer(self, pdf_path: Union[str, Path]) -> str:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        pages = []\n",
    "        for page in doc:\n",
    "            text = page.get_text(\"text\").replace(\"#—! \", \"\")\n",
    "            lines = []\n",
    "            for line in text.splitlines():\n",
    "                l = line.lower()\n",
    "                if any(h.lower() in l for h in self.hospitals): continue\n",
    "                if any(f.lower() in l for f in self.footers): continue\n",
    "                lines.append(line)\n",
    "            pages.append(\"\\n\".join(lines).strip())\n",
    "        return \"\\n\\n\".join(pages)\n",
    "\n",
    "    def match_dmo_section_header(self, line:str):\n",
    "        return self.DMO_HEADER_REGEX.search(re.sub(r\"^[^\\w]*\",\"\",line))\n",
    "\n",
    "    def extract_dmo_sections(self, text:str)->List[str]:\n",
    "        lines = text.splitlines()\n",
    "        sections, current = [], []\n",
    "        inside = False\n",
    "        for line in lines:\n",
    "            s = line.strip()\n",
    "            if len(s)<10: continue\n",
    "            if self._junk_line_re.fullmatch(s): continue\n",
    "            if self.match_dmo_section_header(s):\n",
    "                inside=True\n",
    "                if current: sections.append(\"\\n\".join(current))\n",
    "                current=[s]; continue\n",
    "            if inside:\n",
    "                current.append(s)\n",
    "                if s.upper().startswith(\"LAST UPDATED:\"):\n",
    "                    inside=False\n",
    "                    sections.append(\"\\n\".join(current)); current=[]\n",
    "        if current: sections.append(\"\\n\".join(current))\n",
    "        return sections\n",
    "\n",
    "    def split_into_subsections(self,text:str)->Dict[str,str]:\n",
    "        headers=self.subsections\n",
    "        norm={h.upper():h for h in headers}\n",
    "        pattern=\"(\"+\"|\".join([re.escape(h)+\":?\" for h in headers])+\")\"\n",
    "        parts=re.split(pattern,text,flags=re.IGNORECASE)\n",
    "        subs,buf={},[]; cur=\"General\"\n",
    "        for p in parts:\n",
    "            cand=p.strip().rstrip(\":\")\n",
    "            if cand.upper() in norm:\n",
    "                if buf: subs[cur]=\" \".join(buf).strip(); buf=[]\n",
    "                cur=norm[cand.upper()]\n",
    "            else: buf.append(p)\n",
    "        if buf: subs[cur]=\" \".join(buf).strip()\n",
    "        return {k:v for k,v in subs.items() if v.strip()}\n",
    "\n",
    "    def normalize_formatting(self,text:str)->str:\n",
    "        text=self._date_norm.sub(lambda m:f\"{m.group(3)}-{self.month_map.get(m.group(2),'01')}-{int(m.group(1)):02d}\",text)\n",
    "        for abbr,full in self.abbr_map.items():\n",
    "            text=re.sub(rf\"\\b{re.escape(abbr)}\\b\",full,text)\n",
    "        text=text.replace(\"\\n\",\" \")\n",
    "        return self._non_ascii.sub(\"\",text)\n",
    "\n",
    "    def parse_dmo_metadata(self,sec:str)->Tuple[str,str,str]:\n",
    "        d=self._authored_date_re.search(sec)\n",
    "        doc=self._last_updated_re.search(sec)\n",
    "        head=self.match_dmo_section_header(sec.splitlines()[0])\n",
    "        return (d.group(1) if d else \"UNKNOWN\", doc.group(1).strip() if doc else \"UNKNOWN\", head.group(1) if head else \"UNKNOWN\")\n",
    "\n",
    "    def enrich_dmo_entry(self,sec:Dict[str,Union[str,Dict]])->Dict:\n",
    "        subs=self.split_into_subsections(sec[\"text\"])\n",
    "        allergies=\"NKA\" if \"no known allergies\" in sec[\"text\"].lower() else self._allergies_re.search(sec[\"text\"]).group(1).strip() if self._allergies_re.search(sec[\"text\"]) else None\n",
    "        return {**sec,\"subsections\":list(subs.keys()),\"allergies\":allergies,\"text\":subs}\n",
    "\n",
    "    def build_timeline(self,pdf_path:Union[str,Path])->Dict[str,List[Dict]]:\n",
    "        raw=self.extract_text_no_header_footer(pdf_path)\n",
    "        secs=self.extract_dmo_sections(raw)\n",
    "        timeline=defaultdict(list)\n",
    "        for s in secs:\n",
    "            date,doctor,stype=self.parse_dmo_metadata(s)\n",
    "            clean=self.normalize_formatting(s)\n",
    "            entry={\"doctor\":doctor,\"section_type\":stype,\"text\":clean}\n",
    "            enriched=self.enrich_dmo_entry(entry)\n",
    "            timeline[date].append(enriched)\n",
    "        return dict(timeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8qi8tEJxe0T"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i5IWB0bxe-A"
   },
   "outputs": [],
   "source": [
    "# OCR + Classification Utilities\n",
    "def _is_pdf_searchable(p:Union[str,Path])->bool:\n",
    "    try:\n",
    "        d=fitz.open(p)\n",
    "        t=\"\".join(pg.get_text(\"text\") for pg in d).strip()\n",
    "        d.close()\n",
    "        return len(t)>100\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking searchability for {Path(p).name}: {e}\")\n",
    "        return False\n",
    "\n",
    "def _convert_scanned_pdf(fp:Union[str,Path],out:Union[str,Path])->None:\n",
    "    print(f\"Starting OCR for: {Path(fp).name}...\")\n",
    "    ocrmypdf.ocr(fp,out,skip_text=True,tesseract_pagesegmode=6,tesseract_oem=3,optimize=1,progress_bar=False)\n",
    "    print(f\"✅ OCR complete: {Path(out).name}\")\n",
    "\n",
    "def _process_ocr_task(t:Tuple[Path,Path])->Tuple[str,Path,bool]:\n",
    "    src,out=t; name=src.name\n",
    "    if not src.exists(): return (name,src,False)\n",
    "    tgt=out/name\n",
    "    if _is_pdf_searchable(src):\n",
    "        shutil.copy2(src,tgt); return (name,tgt,True)\n",
    "    else:\n",
    "        tgt=out/f\"OCR_{name}\"\n",
    "        try: _convert_scanned_pdf(src,tgt); return (name,tgt,True)\n",
    "        except Exception as e: print(f\"ERROR: {e}\"); return (name,src,False)\n",
    "\n",
    "def _classify_file_type(p:Path)->str:\n",
    "    try:\n",
    "        d=fitz.open(p)\n",
    "        txt=d[0].get_text(\"text\").lower()\n",
    "        sec=txt.splitlines()[1] if len(txt.splitlines())>1 else \"\"\n",
    "        return \"Lab Results\" if \"patient results\" in sec else \"Medical Records\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying {p.name}: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "def _process_single_file(fd:Tuple[str,Path,str])->Dict[str,Any]:\n",
    "    name,path,ftype=fd\n",
    "    try:\n",
    "        parser=LabResultParser() if ftype==\"Lab Results\" else MedicalRecordsParser() if ftype==\"Medical Records\" else None\n",
    "        data=parser.build_timeline(path) if parser else {\"error\":\"Unknown file type\"}\n",
    "        return {\"original_filename\":name,\"file_type\":ftype,\"structured_data\":data}\n",
    "    except Exception as e:\n",
    "        return {\"original_filename\":name,\"file_type\":ftype,\"structured_data\":{\"error\":str(e)}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzdARiD1xjae"
   },
   "source": [
    "## Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2vOjCwc02w-"
   },
   "outputs": [],
   "source": [
    "class PDFUploadProcessor:\n",
    "    def __init__(self,upload_dir:str):\n",
    "        self.input_dir=Path(upload_dir)\n",
    "        self.output_dir=self.input_dir/\"processed_pdfs\"\n",
    "        self.uploaded=list(self.input_dir.glob(\"*.pdf\"))\n",
    "        self.results=[]\n",
    "        if not self.input_dir.is_dir(): raise ValueError(f\"{upload_dir} not a valid directory\")\n",
    "        if not self.uploaded: print(\"No PDF files found in input directory.\")\n",
    "\n",
    "    def convert_files_to_searchable_pdfs(self,multi=False):\n",
    "        self.output_dir.mkdir(parents=True,exist_ok=True)\n",
    "        tasks=[(f,self.output_dir) for f in self.uploaded]\n",
    "        print(f\"\\n--- OCR Conversion (Parallel={multi}) ---\")\n",
    "        if multi and _MP_AVAILABLE:\n",
    "            with Pool(cpu_count()) as pool: pool.map(_process_ocr_task,tasks)\n",
    "        else:\n",
    "            for t in tasks: _process_ocr_task(t)\n",
    "        print(\"OCR Conversion Complete\")\n",
    "\n",
    "    def extract_and_parse_documents(self,multi=False):\n",
    "        files=list(self.output_dir.glob(\"*.pdf\"))\n",
    "        if not files: print(\"No files found for parsing.\"); return []\n",
    "        print(f\"\\n--- Content Extraction & Parsing (Parallel={multi}) ---\")\n",
    "        if multi and _MP_AVAILABLE:\n",
    "            with Pool(cpu_count()) as pool: types=pool.map(_classify_file_type,files)\n",
    "        else: types=[_classify_file_type(f) for f in files]\n",
    "        tasks=[(f.name,f,t) for f,t in zip(files,types)]\n",
    "        if multi and _MP_AVAILABLE:\n",
    "            with Pool(cpu_count()) as pool: res=pool.map(_process_single_file,tasks)\n",
    "        else: res=[_process_single_file(t) for t in tasks]\n",
    "        self.results=res\n",
    "        print(\"Parsing Complete\")\n",
    "        return res\n",
    "\n",
    "    def create_combined_patient_timeline(self)->Dict[str,List[Dict[str,Any]]]:\n",
    "        if not self.results: raise ValueError(\"Run extract_and_parse_documents() first.\")\n",
    "        print(\"\\n--- Creating Unified Patient Timeline ---\")\n",
    "        unified=defaultdict(list)\n",
    "        for r in self.results:\n",
    "            t=r[\"file_type\"]; data=r[\"structured_data\"]; name=r[\"original_filename\"]\n",
    "            if \"error\" in data: continue\n",
    "            for date,records in data.items():\n",
    "                if not isinstance(records,list): continue\n",
    "                for rec in records:\n",
    "                    event={\"record_type\":t,\"source_file\":name}\n",
    "                    event.update(rec if t==\"Medical Records\" else {\"tests\":[rec]})\n",
    "                    unified[date].append(event)\n",
    "        final=dict(unified)\n",
    "        if not final: raise ValueError(\"No extracted information.\")\n",
    "        out=self.output_dir/\"combined_patient_timeline.json\"\n",
    "        with open(out,\"w\",encoding=\"utf-8\") as f: json.dump(final,f,ensure_ascii=False,indent=4)\n",
    "        print(f\"Timeline saved to {out}\")\n",
    "        return final\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ▶️ Notebook Convenience Runner\n",
    "# ============================================\n",
    "def process_uploads(upload_dir:str,run_ocr=True,multi=True)->Dict[str,Any]:\n",
    "    t0=time.time()\n",
    "    p=PDFUploadProcessor(upload_dir)\n",
    "    if run_ocr: p.convert_files_to_searchable_pdfs(multi)\n",
    "    res=p.extract_and_parse_documents(multi)\n",
    "    timeline=p.create_combined_patient_timeline()\n",
    "    print(f\"\\n Total processing time: {time.time()-t0:.2f}s\")\n",
    "    return {\"results\":res,\"timeline\":timeline}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEZoNEf3isP5"
   },
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-6EyGT7iyRD"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sudQhfq2i2Gl"
   },
   "outputs": [],
   "source": [
    "# Check and download required NLTK data\n",
    "def ensure_nltk_data():\n",
    "    \"\"\"Download NLTK tokenizer data with fallback for different versions\"\"\"\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt_tab')\n",
    "        return True\n",
    "    except LookupError:\n",
    "        try:\n",
    "            # Try downloading punkt_tab for newer NLTK versions\n",
    "            nltk.download('punkt_tab')\n",
    "            return True\n",
    "        except:\n",
    "            # Fallback to older punkt tokenizer\n",
    "            try:\n",
    "                nltk.data.find('tokenizers/punkt')\n",
    "                return True\n",
    "            except LookupError:\n",
    "                nltk.download('punkt')\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97SAZ3cli4OV"
   },
   "outputs": [],
   "source": [
    "# Data structures for chunking\n",
    "@dataclass\n",
    "class TextChunk:\n",
    "    \"\"\"Data class to represent a text chunk with metadata\"\"\"\n",
    "    text: str\n",
    "    word_count: int\n",
    "    metadata: Dict = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.metadata is None:\n",
    "            self.metadata = {}\n",
    "        if self.word_count == 0:\n",
    "            self.word_count = len(self.text.split())\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "        \"\"\"Clean and preprocess text\"\"\"\n",
    "        # Replace all newlines with spaces first\n",
    "        text = text.replace('\\n', ' ')\n",
    "        # Remove extra whitespace and newlines '\\n'\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "class TextChunker:\n",
    "    \"\"\"\n",
    "    Chunker that chunks by section or by fixed size with overlap\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chunk_size: int = 256, overlap: int = 8):\n",
    "        \"\"\"\n",
    "        Initialize the TextChunker\n",
    "\n",
    "        Args:\n",
    "            chunk_size: Maximum size of each chunk (in tokens)\n",
    "            overlap: Number of tokens to overlap between chunks\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.overlap = overlap\n",
    "        self.chunks: List[TextChunk] = []\n",
    "\n",
    "    def chunk_by_fixed_size(self, text: str) -> List[TextChunk]:\n",
    "        \"\"\"\n",
    "        Chunk text by fixed token size with overlap\n",
    "\n",
    "        Args:\n",
    "            text: Input text to chunk\n",
    "\n",
    "        Returns:\n",
    "            List of TextChunk objects\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        cleaned_text = clean_text(text)\n",
    "        tokens = word_tokenize(cleaned_text)\n",
    "\n",
    "        start = 0\n",
    "\n",
    "        while start < len(tokens):\n",
    "            # Calculate end position\n",
    "            end = min(start + self.chunk_size, len(tokens))\n",
    "            # Extract chunk tokens\n",
    "            chunk_tokens = tokens[start:end]\n",
    "            # Convert tokens back to text\n",
    "            chunk_text = ' '.join(chunk_tokens)\n",
    "            # Create chunk object\n",
    "            chunk = TextChunk(\n",
    "                text=chunk_text,\n",
    "                word_count=len(chunk_tokens),\n",
    "            )\n",
    "            chunks.append(chunk)\n",
    "            # Move start position with overlap\n",
    "            start = end - self.overlap\n",
    "            # Break if we've reached the end\n",
    "            if end >= len(tokens):\n",
    "                break\n",
    "\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X9QQcfZi8uV"
   },
   "outputs": [],
   "source": [
    "def process_all_medical_records(medical_data: dict, max_tokens: int = 256, overlap: int = 8) -> List[TextChunk]:\n",
    "    \"\"\"\n",
    "    Process medical records from a dictionary structure and create text chunks.\n",
    "\n",
    "    Args:\n",
    "        medical_data (dict): Dictionary containing medical records data\n",
    "        max_tokens (int): Maximum tokens per chunk\n",
    "        overlap (int): Number of overlapping tokens between chunks\n",
    "\n",
    "    Returns:\n",
    "        List[TextChunk]: List of processed text chunks with metadata\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    chunker = TextChunker(chunk_size=max_tokens, overlap=overlap)\n",
    "\n",
    "    # print(\"Processing medical records with metadata...\")\n",
    "\n",
    "    # Process each date section\n",
    "    for date, records in medical_data.items():\n",
    "        print(f\"Processing date: {date}\")\n",
    "\n",
    "        # Process each record within the date\n",
    "        for record_idx, record in enumerate(records):\n",
    "            if not isinstance(record, dict):\n",
    "                continue\n",
    "\n",
    "            record_type = record.get('record_type', '')\n",
    "\n",
    "            text_content = {}\n",
    "\n",
    "            if record_type == 'Lab Results':\n",
    "              doctor = ''\n",
    "              section_type = 'Lab Results'\n",
    "              subsections = []\n",
    "              allergies = ''\n",
    "              tests = record.get('tests', [])\n",
    "              for test in tests:\n",
    "                  test_results = test.get('lab results', {})\n",
    "                  for key, value in test_results.items():\n",
    "                      text_content[key] = value\n",
    "\n",
    "            else: # record_type == 'Medical Records'\n",
    "            # Extract metadata\n",
    "              doctor = record.get('doctor', '')\n",
    "              section_type = record.get('section_type', '')\n",
    "              subsections = record.get('subsections', [])\n",
    "              allergies = record.get('allergies') or ''\n",
    "              text_content = record.get('text', {})\n",
    "\n",
    "            if isinstance(text_content, dict):\n",
    "                for category, category_text in text_content.items():\n",
    "                    if not category_text or not category_text.strip():\n",
    "                        continue\n",
    "\n",
    "                    # Clean the text\n",
    "                    cleaned_text = clean_text(category_text)\n",
    "\n",
    "                    # Calculate token count\n",
    "                    tokens = word_tokenize(cleaned_text)\n",
    "                    tokens_len = len(tokens)\n",
    "\n",
    "                    # Create base metadata for this text chunk\n",
    "                    base_metadata = {\n",
    "                        \"date\": date,\n",
    "                        \"doctor\": doctor,\n",
    "                        \"section_type\": section_type,\n",
    "                        \"text_category\": category,\n",
    "                        \"subsections\": subsections,\n",
    "                        \"allergies\": allergies,\n",
    "                        \"record_index\": record_idx\n",
    "                    }\n",
    "\n",
    "                    if tokens_len <= max_tokens:\n",
    "                        # Single chunk for this category\n",
    "                        chunk = TextChunk(\n",
    "                            text=cleaned_text,\n",
    "                            word_count=tokens_len,\n",
    "                            metadata={**base_metadata, \"chunk\": 1, \"total_chunks\": 1}\n",
    "                        )\n",
    "                        all_chunks.append(chunk)\n",
    "                        # print(f\"  {category}: Single chunk ({tokens_len} tokens)\")\n",
    "                    else:\n",
    "                        # Multiple chunks needed for this category\n",
    "                        category_chunks = chunker.chunk_by_fixed_size(cleaned_text)\n",
    "\n",
    "                        # Update metadata for each chunk\n",
    "                        for chunk_idx, chunk in enumerate(category_chunks, 1):\n",
    "                            chunk.metadata = {\n",
    "                                **base_metadata,\n",
    "                                \"chunk\": chunk_idx,\n",
    "                                \"total_chunks\": len(category_chunks)\n",
    "                            }\n",
    "\n",
    "                        all_chunks.extend(category_chunks)\n",
    "                        # print(f\"  {category}: {len(category_chunks)} chunks ({tokens_len} tokens total)\")\n",
    "\n",
    "    print(f\"Completed. Total chunks: {len(all_chunks)}\")\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOdGj7M2i9gB"
   },
   "outputs": [],
   "source": [
    "def prepare_chunks_for_embedding(chunks: List[TextChunk]) -> List[Dict]:\n",
    "    prepared_chunks = []\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Generate unique ID using index, date, category, and chunk number\n",
    "        chunk_id = i + 1\n",
    "        if chunk.metadata and 'date' in chunk.metadata:\n",
    "            # Include text_category to avoid duplicates from same date/chunk\n",
    "            category = chunk.metadata.get('text_category', 'unknown')\n",
    "            chunk_num = chunk.metadata.get('chunk', 1)\n",
    "            chunk_id = f\"{chunk.metadata['date']}_{category}_chunk_{chunk_num}_{i}\"\n",
    "        prepared_chunk = {\n",
    "            'id': chunk_id,\n",
    "            'text': chunk.metadata['date'] + \", \" + chunk.metadata['text_category'] + \": \" + chunk.text,\n",
    "            'metadata': {\n",
    "                **chunk.metadata\n",
    "            }\n",
    "        }\n",
    "        prepared_chunks.append(prepared_chunk)\n",
    "\n",
    "    return prepared_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBF-NKCvi_ou"
   },
   "outputs": [],
   "source": [
    "# Embedding Generation using Bio_ClinicalBERT\n",
    "# from sentence_transformers import SentenceTransformer, models\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def build_bioclinical_sentence_model(max_seq_len: int = 384):\n",
    "    word_emb = models.Transformer(\"emilyalsentzer/Bio_ClinicalBERT\", max_seq_length=max_seq_len)\n",
    "    pooling = models.Pooling(\n",
    "        word_emb.get_word_embedding_dimension(),\n",
    "        pooling_mode_mean_tokens=True,\n",
    "        pooling_mode_cls_token=False,\n",
    "        pooling_mode_max_tokens=False,\n",
    "    )\n",
    "    return SentenceTransformer(modules=[word_emb, pooling])\n",
    "\n",
    "def generate_embeddings(prepared_chunks: List[Dict], model_name: str = \"emilyalsentzer/Bio_ClinicalBERT\") -> List[Dict]:\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    model = build_bioclinical_sentence_model()\n",
    "\n",
    "    # Check if GPU is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # model = model.to(device)\n",
    "    # print(f\"Device: {device}\")\n",
    "\n",
    "    # Extract texts for embedding\n",
    "    texts = [chunk['text'] for chunk in prepared_chunks]\n",
    "\n",
    "    print(f\"Processing {len(texts)} text chunks...\")\n",
    "    # start_time = time.time()\n",
    "\n",
    "    # Generate embeddings for all texts\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        convert_to_tensor=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    # Convert to CPU and numpy for storage\n",
    "    embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "    # end_time = time.time()\n",
    "    # print(f\"Embedding generation completed in {end_time - start_time:.1f}s\")\n",
    "    # print(f\"Vector dimension: {len(embeddings[0])}\")\n",
    "\n",
    "    # Add embeddings to chunks\n",
    "    embedded_chunks = []\n",
    "    for chunk, embedding in zip(prepared_chunks, embeddings):\n",
    "        embedded_chunk = {\n",
    "            **chunk,\n",
    "            'embedding': embedding.tolist(),  # Convert numpy array to list for JSON serialization\n",
    "            'embedding_model': \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "            'embedding_dimension': len(embedding)\n",
    "        }\n",
    "        embedded_chunks.append(embedded_chunk)\n",
    "\n",
    "    return embedded_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqwY3pLtjC-7"
   },
   "outputs": [],
   "source": [
    "# Vector Database Storage using Milvus Lite\n",
    "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility\n",
    "import uuid\n",
    "\n",
    "class MilvusVectorStore:\n",
    "\n",
    "    def __init__(self, collection_name: str = \"medical_rag_embeddings\", db_file: str = \"./milvus_lite.db\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.db_file = db_file\n",
    "        self.collection = None\n",
    "\n",
    "    def connect(self):\n",
    "        try:\n",
    "            connections.connect(\"default\", uri=self.db_file)\n",
    "            print(f\"Connected to Milvus Lite at {self.db_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Connection failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    def create_collection(self, embedding_dim: int = 768):\n",
    "        # Drop existing collection if it exists\n",
    "        if utility.has_collection(self.collection_name):\n",
    "            utility.drop_collection(self.collection_name)\n",
    "            print(f\"Removed existing collection: {self.collection_name}\")\n",
    "\n",
    "        # Define schema\n",
    "        fields = [\n",
    "            FieldSchema(name=\"id\", dtype=DataType.VARCHAR, max_length=200, is_primary=True),\n",
    "            FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=10000),\n",
    "            FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),\n",
    "            FieldSchema(name=\"date\", dtype=DataType.VARCHAR, max_length=50),\n",
    "            FieldSchema(name=\"chunk_number\", dtype=DataType.INT64),\n",
    "            FieldSchema(name=\"word_count\", dtype=DataType.INT64),\n",
    "        ]\n",
    "\n",
    "        schema = CollectionSchema(fields, f\"Medical RAG embeddings collection with {embedding_dim}D vectors\")\n",
    "\n",
    "        # Create collection\n",
    "        self.collection = Collection(self.collection_name, schema)\n",
    "        # print(f\"Collection created: {self.collection_name}\")\n",
    "\n",
    "        # Create index for vector search\n",
    "        index_params = {\n",
    "            \"index_type\": \"FLAT\",\n",
    "            \"metric_type\": \"COSINE\",\n",
    "            \"params\": {}\n",
    "        }\n",
    "\n",
    "        self.collection.create_index(\"embedding\", index_params)\n",
    "        # print(\"Vector index ready\")\n",
    "\n",
    "    def insert_embeddings(self, embedded_chunks: List[Dict]):\n",
    "        \"\"\"\n",
    "        Insert embedded chunks into Milvus collection\n",
    "\n",
    "        Args:\n",
    "            embedded_chunks: List of chunks with embeddings\n",
    "        \"\"\"\n",
    "        if not self.collection:\n",
    "            print(\"Collection not initialized. Call create_collection() first.\")\n",
    "            return\n",
    "\n",
    "        # Prepare data for insertion\n",
    "        ids = []\n",
    "        texts = []\n",
    "        embeddings = []\n",
    "        dates = []\n",
    "        chunk_numbers = []\n",
    "        word_counts = []\n",
    "        i = 0\n",
    "        for chunk in embedded_chunks:\n",
    "            # Generate unique ID if not present\n",
    "            chunk_id = chunk.get('id', str(uuid.uuid4()))\n",
    "\n",
    "            ids.append(str(chunk_id))\n",
    "            texts.append(chunk['text'][:9999])  # Truncate if too long\n",
    "            embeddings.append(chunk['embedding'])\n",
    "            dates.append(chunk['metadata'].get('date', 'unknown'))\n",
    "            chunk_numbers.append(chunk['metadata'].get('chunk', 1))\n",
    "            word_counts.append(chunk['metadata'].get('word_count', 0))\n",
    "\n",
    "        # Insert data\n",
    "        data = [ids, texts, embeddings, dates, chunk_numbers, word_counts]\n",
    "\n",
    "        try:\n",
    "            insert_result = self.collection.insert(data)\n",
    "            self.collection.flush()\n",
    "            print(f\"Data inserted ({len(embedded_chunks)} chunks)\")\n",
    "            # print(f\"Sample IDs: {insert_result.primary_keys[:3]}...\" if len(insert_result.primary_keys) > 3 else f\"IDs: {insert_result.primary_keys}\")\n",
    "\n",
    "            self.load_collection()\n",
    "            # print(f\"Loaded into memory for search\")\n",
    "            return insert_result\n",
    "        except Exception as e:\n",
    "            print(f\"Insert failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def load_collection(self):\n",
    "        if self.collection:\n",
    "            self.collection.load()\n",
    "            # print(\"Collection loaded into memory\")\n",
    "\n",
    "    def search_similar(self, query_embedding: List[float], top_k: int = 8, date_filter: str = None):\n",
    "        if not self.collection:\n",
    "            print(\"Collection not initialized\")\n",
    "            return []\n",
    "\n",
    "        search_params = {\"metric_type\": \"COSINE\", \"params\": {}}\n",
    "\n",
    "        # Optional date filtering\n",
    "        expr = None\n",
    "        if date_filter:\n",
    "            expr = f'date == \"{date_filter}\"'\n",
    "        results = self.collection.search(\n",
    "            [query_embedding],\n",
    "            \"embedding\",\n",
    "            search_params,\n",
    "            limit=top_k,\n",
    "            expr=expr,\n",
    "            output_fields=[\"text\", \"date\", \"chunk_number\", \"word_count\"]\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def get_collection_stats(self):\n",
    "        if self.collection:\n",
    "            self.collection.flush()\n",
    "            stats = self.collection.num_entities\n",
    "            print(f\"Collection '{self.collection_name}' contains {stats} vectors\")\n",
    "            return stats\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0c4Yh81jDle"
   },
   "outputs": [],
   "source": [
    "# RAG Pipeline - Retrieval System for Medical Form Fields\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import json\n",
    "\n",
    "class MedicalRAGRetriever:\n",
    "\n",
    "    def __init__(self, vector_store, embedding_model_name: str = \"emilyalsentzer/Bio_ClinicalBERT\"):\n",
    "\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_model = build_bioclinical_sentence_model()\n",
    "\n",
    "        # Move to GPU if available\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.embedding_model = self.embedding_model.to(device)\n",
    "\n",
    "        print(f\"RAG Retriever initialized ({embedding_model_name})\")\n",
    "        # print(f\"Device: {device}\")\n",
    "\n",
    "    def generate_query_embedding(self, query: str) -> List[float]:\n",
    "        embedding = self.embedding_model.encode(query, convert_to_tensor=True)\n",
    "        return embedding.cpu().numpy().tolist()\n",
    "\n",
    "    def retrieve_for_queries(self, queries: List[str], top_k: int) -> Dict:\n",
    "        all_chunks = []\n",
    "\n",
    "        for i, query in enumerate(queries):\n",
    "            print(f\"Processing query {i+1}/{len(queries)}: {query[:50]}...\")\n",
    "\n",
    "            # Generate embedding for the query\n",
    "            query_embedding = self.generate_query_embedding(query)\n",
    "\n",
    "            # Simple search for top 2 results\n",
    "            results = self.vector_store.search_similar(query_embedding, top_k=top_k)\n",
    "            chunks = self._process_search_results(results)\n",
    "\n",
    "            if chunks:\n",
    "                all_chunks.extend(chunks)\n",
    "\n",
    "        # Remove duplicates based on chunk_id\n",
    "        seen_ids = set()\n",
    "        unique_chunks = []\n",
    "        for chunk in all_chunks:\n",
    "            if chunk['chunk_id'] not in seen_ids:\n",
    "                unique_chunks.append(chunk)\n",
    "                seen_ids.add(chunk['chunk_id'])\n",
    "\n",
    "        # Aggregate text from all unique chunks\n",
    "        aggregated_text = \"\\n\\n\".join([chunk['text'] for chunk in unique_chunks])\n",
    "\n",
    "        return {\n",
    "            'queries': queries,\n",
    "            'retrieved_chunks': unique_chunks,\n",
    "            'aggregated_text': aggregated_text,\n",
    "            'chunk_count': len(unique_chunks)\n",
    "        }\n",
    "\n",
    "    def _process_search_results(self, results) -> List[Dict]:\n",
    "        chunks = []\n",
    "        for hits in results:\n",
    "            for hit in hits:\n",
    "                chunks.append({\n",
    "                    'text': hit.entity.get('text', ''),\n",
    "                    'score': float(hit.score),\n",
    "                    'date': hit.entity.get('date', 'unknown'),\n",
    "                    'chunk_number': hit.entity.get('chunk_number', 0),\n",
    "                    'word_count': hit.entity.get('word_count', 0),\n",
    "                    'chunk_id': hit.id\n",
    "                })\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCvN2YvbjGw-"
   },
   "outputs": [],
   "source": [
    "def retrieve_rag(timeline, field_sets, top_k=2, chunk_size=256, overlap=8):\n",
    "\n",
    "    ensure_nltk_data()\n",
    "\n",
    "    # Process using the timeline variable\n",
    "    all_processed_chunks = process_all_medical_records(timeline, chunk_size, overlap)\n",
    "\n",
    "    # Prepare chunks for the next stage of RAG pipeline (embedding generation)\n",
    "    prepared_for_embedding = prepare_chunks_for_embedding(all_processed_chunks)\n",
    "\n",
    "    # Generate embeddings for all prepared chunks\n",
    "    embedded_chunks = generate_embeddings(prepared_for_embedding)\n",
    "\n",
    "    # Show sample embedded chunk structure (without the full embedding vector)\n",
    "    sample_chunk = embedded_chunks[0].copy()\n",
    "    sample_chunk['embedding'] = f\"[{len(sample_chunk['embedding'])}-dim vector]\"\n",
    "\n",
    "    # Initialize and setup Milvus Lite vector database\n",
    "    vector_store = MilvusVectorStore()\n",
    "\n",
    "    # Connect to Milvus Lite\n",
    "    if vector_store.connect():\n",
    "        # Create collection with appropriate embedding dimension\n",
    "        embedding_dim = embedded_chunks[0]['embedding_dimension'] if embedded_chunks else 768\n",
    "        vector_store.create_collection(embedding_dim)\n",
    "\n",
    "        # Insert all embeddings\n",
    "        insert_result = vector_store.insert_embeddings(embedded_chunks)\n",
    "\n",
    "        if insert_result:\n",
    "            # Load collection for search\n",
    "            vector_store.load_collection()\n",
    "\n",
    "            # Get statistics\n",
    "            vector_store.get_collection_stats()\n",
    "        else:\n",
    "            print(\"Failed to insert embeddings\")\n",
    "    else:\n",
    "        print(\"Could not connect to Milvus\")\n",
    "\n",
    "    # Initialize the retriever\n",
    "    if 'vector_store' in locals() and hasattr(vector_store, 'collection') and vector_store.collection:\n",
    "        retriever = MedicalRAGRetriever(vector_store)\n",
    "\n",
    "        # Store retrieval results for all field sets\n",
    "        all_retrieval_results = {}\n",
    "\n",
    "        # Process each field set\n",
    "        for field_num, field_queries in field_sets.items():\n",
    "            retrieval_result = retriever.retrieve_for_queries(field_queries, top_k)\n",
    "            all_retrieval_results[field_num] = retrieval_result\n",
    "\n",
    "        return all_retrieval_results\n",
    "\n",
    "    else:\n",
    "        print(\"Vector store not available. Run the database setup cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IV8POv0_8J7z"
   },
   "source": [
    "### NTUC RAG Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl7fx1yIjJdg"
   },
   "outputs": [],
   "source": [
    "NTUC_FIELD_JSON_1 = [\"Over what period do your records extend? Start date (dd/mm/yyyy):\" ,\n",
    "                \"Over what period do your records extend? End date (dd/mm/yyyy):\",\n",
    "                \"When did the Insured first consult you for this condition? (dd/mm/yyyy)\",\n",
    "                \"When you first saw the Insured, what were the symptoms presented and their duration?, symptoms presented, Duration of symptom, Date symptoms first occurred (dd/mm/yyyy)\"]\n",
    "NTUC_FIELD_JSON_2 = [\n",
    "    \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you?\",\n",
    "    \"Details of other doctors consulted (rows), Name of doctor, Name and address of clinic / hospital, Date(s) of consultation (dd/mm/yyyy), Diagnosis made\",\n",
    "    \"Histological diagnosis of disease, Date of diagnosis (dd/mm/yyyy), Doctor and clinic / hospital where diagnosis was first made, Date Insured was first informed of diagnosis (dd/mm/yyyy)\",\n",
    "    \"Was a biopsy of the tumour performed?, Biopsy date (dd/mm/yyyy), If No, how was the diagnosis confirmed?\",\n",
    "    \"Site or organ involved\",\n",
    "    \"Staging of tumour, Has the cancer spread beyond the layer of cells?, Was the disease completely localised?, Was there invasion of adjacent tissues?, Were regional lymph nodes involved?, Were there distant metastases?, Metastases details\",\n",
    "    \"Is the condition carcinoma-in-situ?\",\n",
    "    \"Is the condition Pre-malignant / non-invasive\",\n",
    "    \"Is the condition Borderline / suspicious malignancy\",\n",
    "    \"Is the condition Cervical dysplasia CIN1-3 (without CIS)\"\n",
    "]\n",
    "NTUC_FIELD_JSON_3 = [\n",
    "\"Is the condition Carcinoma-in-situ of biliary system\",\n",
    "\"Is the conditionHyperkeratoses, basal/squamous skin cancers\",\n",
    "\"Is the condition Bladder cancer T1N0M0 or below, Bladder papillary micro-carcinoma\",\n",
    "\"Is the condition Prostate cancer T1N0M0, T1, or a equivalent or lesser classification?, T1 subclass\",\n",
    "\"Is the condition Thyriod cancer T1N0M0 or below?, Thyriod diameter, Is Thyroid papillary micro-carcinoma?, Thyroid papillary micro-carcinoma size\",\n",
    "\"If the diagnosis is Leukaemia, state type, Leukaemia RAI staging\",\n",
    "\"If the diagnosis is Melanoma, size/thickness (Breslow mm), Melanoma Clark level, Has the condition caused invasion beyond the epidermis?\"\n",
    "\"If the condition is GIST TNM, classification, GIST mitotic count (HPF)\",\n",
    "\"Has the patient received treatment for this illness?, Treatment type, Date of treatment (dd/mm/yyyy), Duration of treatment, Has active treatment and therapy been rejected in favour of symptoms relief, Active treatment rejection reason\",\n",
    "\"Was radical surgery done?, Radical surgery code/table, Radical surgery date (dd/mm/yyyy)\"\n",
    "]\n",
    "NTUC_FIELD_JSON_4 = [\n",
    "\"Is the Insured still on follow-up at your clinic? (follow-up/discharge), Next appointment date (dd/mm/yyyy), Discharge date (dd/mm/yyyy)\",\n",
    "\"Is the Insured terminally ill (i.e. death expected within 12 months)?, Terminal illness evaluation, Terminal illness assessment date (dd/mm/yyyy)\",\n",
    "\"Is the Insured referred to hospice care? Hospice name, Hospice inpatient admission date (dd/mm/yyyy), Hospice daycare start date (dd/mm/yyyy), Hospice care type\",\n",
    "\"Details of Doctors and clinics / hospitals consulted for this condition, Name of doctorName and Address of Clinic/Hospital, Date(s) of consultation (dd/mm/yyyy), Diagnosis made\",\n",
    "\"Has insured ever had Malignant, pre-malignant or other related conditions or risk factors?, Malignant, pre-malignant or other related conditions or risk factors details\",\n",
    "\"Details of Medical history that would have increased the risk of cancer\",\n",
    "\"Details of Family history that would have increased the risk of Cancer\",\n",
    "\"Details of habits related to Smoking habits\",\n",
    "\"Details of habits related to Alcohol consumption habits\",\n",
    "\"Is the tumour or cancer in any way caused directly or indirectly by alcohol or drug abuse?, Alcohol/drug abuse details\"\n",
    "]\n",
    "NTUC_FIELD_JSON_5 = [\n",
    "\"Tumour caused by HIV or AIDS?, HIV antibody status, HIV/AIDS diagnosis date (dd/mm/yyyy)\",\n",
    "\"Any other significant health conditions\",\n",
    "\"Details of other health conditions (rows), Diagnosis, Name of doctor, Name/address of clinic/hospital, Date of diagnosis (dd/mm/yyyy), Duration of condition, Treatment received\"\n",
    "]\n",
    "\n",
    "ntuc_queries = {\n",
    "1: NTUC_FIELD_JSON_1,\n",
    "2: NTUC_FIELD_JSON_2,\n",
    "3: NTUC_FIELD_JSON_3,\n",
    "4: NTUC_FIELD_JSON_4,\n",
    "5: NTUC_FIELD_JSON_5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxJZL2Bd8ORz"
   },
   "source": [
    "### GE RAG PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r58lbnSp8Pb3"
   },
   "outputs": [],
   "source": [
    "GE_FIELD_JSON_1 = [\n",
    "    \"Date when insured first consulted you for cancer (ddmmyyyy)\",\n",
    "    \"Symptoms presented and the date they first appeared?\",\n",
    "    \"Source of above information\",\n",
    "    \"What is the source of the above information? If Referring Doctor / Others, specify name & address\",\n",
    "    \"Date when Cancer was FIRST diagnosed (ddmmyyyy)\",\n",
    "    \"Diagnosis was first made by (name of Doctor)\"\n",
    "]\n",
    "\n",
    "GE_FIELD_JSON_2 = [\n",
    "    \"Actual diagnosis\",\n",
    "    \"Date when insured first became aware of this illness (ddmmyyyy)\",\n",
    "    \"Was the illness suffered by Life Assured caused directly or indirectly by alcohol or drug abuse?\",\n",
    "    \"If illness caused directly or indirectly by alcohol or drug abuse, please give details\",\n",
    "    \"What is the staging of the tumour?\",\n",
    "    \"Please state the tumour classification (eg TMN classification etc)\",\n",
    "    \"Was the cancer completely localised?\",\n",
    "    \"Was there invasion of tissues?\",\n",
    "    \"Were regional lymph nodes involved?\",\n",
    "    \"Were there distant metastases?\",\n",
    "    \"Did the Life Assured undergo any surgery?\",\n",
    "    \"Date of surgery (ddmmyyyy)\",\n",
    "    \"Surgical procedure performed\",\n",
    "    \"Was there any other mode of treatment, other than surgery, which could be undertaken to treat the Life Assured’s condition?\",\n",
    "    \"Type of treatment other than surgery that could be undertaken to treat condition\"\n",
    "]\n",
    "\n",
    "GE_FIELD_JSON_3 = [\n",
    "    \"Has the Life Assured underwent other mode of treatment?\",\n",
    "    \"Date of other treatment (ddmmyyyy)\",\n",
    "    \"Reason for no other mode of treatment\",\n",
    "    \"What other forms of treatment did the Life Assured undergo (eg chemotherapy, radiotherapy etc)?\",\n",
    "    \"If diagnosis is leukaemia, please provide the type of leukaemia\",\n",
    "    \"If the diagnosis is malignant melanoma, please give full details of size, thickness (Breslow classification) and/or depth of invasion (Clark level)\",\n",
    "    \"Is the diagnosis related to Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)?\",\n",
    "    \"Date of diagnosis for HIV/AIDS (ddmmyyyy)\",\n",
    "    \"Life Assured’s mental and cognitive abiliites\",\n",
    "    \"Is Life Assured mentally incapacitated?\"\n",
    "]\n",
    "\n",
    "GE_FIELD_JSON_4 = [\n",
    "    \"Does Life Assured have any other medical conditions?\",\n",
    "    \"Medical conditions\",\n",
    "    \"Does Life Assured have any family history?\",\n",
    "    \"Family History\",\n",
    "    \"Details of the Life Assured’s habits in relation to cigarette smoking, including the duration of smoking habit, number of cigarettes smoked per day and source of information\",\n",
    "    \"Details of the Life Assured’s habit in relation to alcohol consumption including the amount of alcohol consumption per day and source of information\",\n",
    "    \"Please provide any other information which may be of assistance to us in assessing this claim\"\n",
    "]\n",
    "\n",
    "ge_queries = {\n",
    "1: GE_FIELD_JSON_1,\n",
    "2: GE_FIELD_JSON_2,\n",
    "3: GE_FIELD_JSON_3,\n",
    "4: GE_FIELD_JSON_4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzhAek9j8pU9"
   },
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9W_Ki12M98w"
   },
   "source": [
    "## Meta Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBAVr_TBNFXU"
   },
   "outputs": [],
   "source": [
    "META_RULES = \"\"\"\n",
    "You are a precise clinical information extraction assistant.\n",
    "Return ONLY valid JSON. Do not include markdown, comments, or explanations.\n",
    "\n",
    "META RULES (apply to all fields):\n",
    "- Output MUST be a single JSON object with ALL target keys present.\n",
    "- Every field must be represented as an object with two keys:\n",
    "- \"value\": the extracted string or \"Yes\"/\"No\"\n",
    "- \"confidence\": a floating-point probability between 0 and 1 (e.g., 0.85), which should reflect probability that YOUR answer is correct. you are to generate this value\n",
    "- Yes/No questions:\n",
    "  - \"value\" MUST be \"Yes\" or \"No\".\n",
    "  - If the notes explicitly confirm → \"Yes\".\n",
    "  - If there is explicit denial (e.g., “no history of…”, “denies…”) OR the field is unrelated or not mentioned at all in the notes -> \"No\"\n",
    "  - If “No” is chosen purely because of absence of mention,\n",
    "    confidence should be capped at 0.5 to reflect uncertainty.\n",
    "  - Always consider “No” the *default absence state*, not an explicit negation.ß\n",
    "- Extraction hierarchy for patient tumour site/histology/staging:\n",
    "1) DIAGNOSIS SUMMARY → use exact strings for “Primary Site”, “Diagnosis”.\n",
    "2) CLINICAL AND TREATMENT SUMMARY → use ONLY the segment BEFORE the token \"family history:\".\n",
    "3) Pathology/biopsy sections\n",
    "4) Imaging IMPRESSION lines that clearly refer to the patient, not relatives.\n",
    "- Family history handling:\n",
    "- Ignore content AFTER \"family history:\" when filling patient fields.\n",
    "- Text with family markers [\"family history\", \"FH\", \"mother\", \"father\", \"sibling\", \"aunt\",\n",
    "\"uncle\", \"cousin\", \"grandmother\", \"grandfather\", \"relative\"] must NOT be used for patient fields.\n",
    "- You WILL still extract family-history/risk-factor answers when those specific questions come later.\n",
    "- For non-binary fields:\n",
    "- If a value is unknown or not stated, use \"\" for \"value\" (not null).\n",
    "- Still provide a \"confidence\" score (e.g., 0.5 if very uncertain).\n",
    "- If conflicting mentions exist, the LAST appointment’s explicit patient diagnosis/site wins.\n",
    "- Use exact phrases from the notes where possible (e.g., “HER2 3+ (Positive)”).\n",
    "- Keep dates exactly as they appear in the notes; do not reformat.\n",
    "- Do NOT invent or infer information beyond the yes/no rule.\n",
    "- Do NOT add extra keys or structures.\n",
    "\n",
    "Remember, return ONLY valid JSON. DO NOT include markdown, comments, or explanations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTUC META PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdMCLQ9LNF6G"
   },
   "outputs": [],
   "source": [
    "NTUC_FIELD_JSON_WITH_INLINE_1 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "\"Over what period do your records extend? Start date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",                // Find the EARLIEST \"Visit/Appointment Date\" or \"Authored:\" date\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Over what period do your records extend? End date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",                // Find the LATEST \"Visit/Appointment Date\" or \"Authored:\" date.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"When did the Insured first consult you for this condition? (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",                // Earliest consult date associated with the condition\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\n",
    "\"When you first saw the Insured, what were the symptoms presented and their duration? (rows 0..2)\": [\n",
    "    // Rules:\n",
    "    // - If no symptoms are stated → return [].\n",
    "    // - If exactly one symptom is stated → return ONE object (length = 1).\n",
    "    // - If two or more symptoms are stated → return TWO objects (take the first two).\n",
    "    // - Keep date strings exactly as in the notes; do not reformat.\n",
    "    {\n",
    "        \"Symptom presented\": {\n",
    "            // CRITICAL: Initial symptom that led to the diagnosis.\n",
    "            // DO NOT extract treatment side effects (e.g., \"nausea\", \"mucositis\", \"rash\") that appear after a treatment is mentioned.\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Duration of symptom\": {\n",
    "            \"value\": \"\",               // Copy duration associated with this symptom\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Date of onset (dd/mm/yyyy)\": {\n",
    "            \"value\": \"\",               // Keep date text as-is\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    }\n",
    "    // Add a second object ONLY if there is a second symptom to capture.\n",
    "]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "NTUC_FIELD_JSON_WITH_INLINE_2 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "\"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you?\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Details of other doctors consulted (rows 0..3)\": [\n",
    "    // Rules:\n",
    "    // - If no consultation → return []\n",
    "    // - If consultations exist → return 1..3 row objects (as many as are clearly present, capped at 3)\n",
    "    {\n",
    "        \"Name of doctor\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Name and address of clinic / hospital\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Date(s) of consultation (dd/mm/yyyy)\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Diagnosis made\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    }\n",
    "    // Add a second/third object ONLY if multiple consultations are clearly present\n",
    "],\n",
    "\"Histological diagnosis\": {\n",
    "    \"value\": \"\",           // Extract overall diagnosis from DIAGNOSIS SUMMARY\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Date of diagnosis (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           // Copy date associated with diagnosis given\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Doctor/clinic where diagnosis was first made\": {\n",
    "    \"value\": \"\",           // Look for doctor/clinic names for the first diagnosis or biopsy.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Date Insured was first informed of diagnosis (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Was a biopsy of the tumour performed?\": {\n",
    "    \"value\": \"\",           // \"Yes\" if \"biopsy\", \"cnb\", \"TBLB\", or \"Surgical resection\" is mentioned.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Biopsy date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           // Only if previous == \"Yes\"; keep original date format of biopsy\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"If No, how was the diagnosis confirmed?\": {\n",
    "    \"value\": \"\",           // Only if previous == \"No\"; copy explanation verbatim if present\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Site or organ involved\": {\n",
    "    \"value\": \"\",           // Extract from \"Primary Site\" in \"DIAGNOSIS SUMMARY\". Patient site ONLY.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Staging\": {\n",
    "    \"value\": \"\",           // Extract TNM staging from \"DIAGNOSIS SUMMARY\" or \"CLINICAL AND TREATMENT SUMMARY\".\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Has the cancer spread beyond the layer of cells?\": {\n",
    "    \"value\": \"\",           // \"Yes\" if diagnosis is \"Invasive\" or staging is T1 or higher. \"No\" if \"in-situ\".\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Was the disease completely localised?\": {\n",
    "    \"value\": \"\",           // \"Yes\" if staging is N0 AND M0. \"No\" if N is 1+ OR M is 1+.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Was there invasion of adjacent tissues?\": {\n",
    "    \"value\": \"\",           // \"Yes\" if staging is T4.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Were regional lymph nodes involved?\": {\n",
    "    \"value\": \"\",           // \"N0\" means \"No\". \"N1\" or \"N2\" means \"Yes\". Prioritize final staging over speculative notes.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Were there distant metastases?\": {\n",
    "    \"value\": \"\",           // \"M0\" means \"No\". \"M1\" means \"Yes\". Prioritize final staging.\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Metastases details\": {\n",
    "    \"value\": \"\",           // Only if previous == \"Yes\"; copy verbatim details (e.g., \"liver and lung metastases\")\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Is the condition carcinoma-in-situ?\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Pre-malignant / non-invasive\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Borderline / suspicious malignancy\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Cervical dysplasia CIN1-3 (without CIS)\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "NTUC_FIELD_JSON_WITH_INLINE_3 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "\"Carcinoma-in-situ of biliary system\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Hyperkeratoses, basal/squamous skin cancers\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Bladder cancer T1N0M0 or below\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Bladder papillary micro-carcinoma\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Is Prostate cancer T1N0M0, T1, or a equivalent or lesser classification?\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"T1 subclass\": {\n",
    "    \"value\": \"\",           // Only fill if previous == \"Yes\" (T1a / T1b / T1c)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Is Thyriod cancer T1N0M0 or below?\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Thyriod diameter\": {\n",
    "    \"value\": \"\",           // Only fill if previous == \"Yes\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Is Thyroid papillary micro-carcinoma?\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Thyroid papillary micro-carcinoma size\": {\n",
    "    \"value\": \"\",           // Only fill if previous == \"Yes\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Leukaemia type\": {\n",
    "    \"value\": \"\",           // Leave blank if not applicable\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Leukaemia RAI staging\": {\n",
    "    \"value\": \"\",           // Leave blank if not applicable\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Melanoma size/thickness (Breslow mm)\": {\n",
    "    \"value\": \"\",           // Leave blank if not applicable\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Melanoma Clark level\": {\n",
    "    \"value\": \"\",           // Leave blank if not applicable\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Has the condition caused invasion beyond the epidermis?\": {\n",
    "    \"value\": \"\",           // Allowed values: \"Yes\" / \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"GIST TNM classification\": {\n",
    "    \"value\": \"\",           // Only if diagnosis is Gastro-Intestinal Stroma Tumour (GIST)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"GIST mitotic count (HPF)\": {\n",
    "    \"value\": \"\",           // Only if diagnosis is GIST\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Has the patient received treatment for this illness? (rows 0..3)\": [\n",
    "    # Rules:\n",
    "    # - If no treatment → return []\n",
    "    # - If treatment exists → return 1..3 row objects (capped at 3)\n",
    "    # - Keep date strings exactly as in notes\n",
    "    {\n",
    "        \"Treatment type\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Date of treatment (dd/mm/yyyy)\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Duration of treatment\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    }\n",
    "    # Add a second/third object ONLY if multiple distinct treatments are clearly present\n",
    "],\n",
    "\"Has active treatment and therapy been rejected in favour of symptoms relief\": {\n",
    "    \"value\": \"\",           # Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Active treatment rejection reason\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; copy verbatim\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Was radical surgery done?\": {\n",
    "    \"value\": \"\",           # Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Radical surgery code/table\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; copy verbatim\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Radical surgery date date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; keep original date format\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"For mastectomy cases, was reconstrucive surgery done or recommended?\": {\n",
    "    \"value\": \"\",           # Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Reconstructive surgery date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; keep original date format\n",
    "    \"confidence\": 0.0\n",
    "}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "NTUC_FIELD_JSON_WITH_INLINE_4 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "\"Is the Insured still on follow-up at your clinic?\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Next appointment date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           // Only if follow-up == \"Yes\"; leave blank if \"No\" or not stated\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Discharge date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           // Only if follow-up == \"No\"; leave blank if \"Yes\" or not stated\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Is the Insured terminally ill (i.e. death expected within 12 months)?\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Terminal illness evaluation\": {\n",
    "    \"value\": \"\",           // Only if terminally ill == \"Yes\"; verbatim if present\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Terminal illness assessment date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           // Only if terminally ill == \"Yes\"; keep original date format\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Is the Insured referred to hospice care?\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Hospice name\": {\n",
    "    \"value\": \"\",           // Only if hospice care == \"Yes\"; copy verbatim\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Hospice care type - Inpatient\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"\"; \"Yes\" if inpatient ticked. Only for this field, not inpatient, do not give \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Hospice inpatient admission date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           // Only if Hospice care type - Inpatient == \"Yes\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Hospice care type - Day care\": {\n",
    "    \"value\": \"\",           // Allowed: \"Yes\" / \"\"; \"Yes\" if day care ticked. Only for this field, not day care, do not give \"No\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Hospice daycare start date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           // Only if Hospice care type - Day care == \"Yes\"\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Doctors/hospitals consulted for this condition (rows 0..3)\": [\n",
    "    // Rules:\n",
    "    // - If no other doctors/hospitals consulted → return []\n",
    "    // - If other doctors/hospitals consulted → return 1..3 row objects (as many as are clearly present, capped at 3)\n",
    "    {\n",
    "        \"Name of doctor\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Name and Address of Clinic/Hospital\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Date(s) of consultation (dd/mm/yyyy)\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Diagnosis made\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    }\n",
    "    // Add a second/third object only if multiple consultations are clearly present\n",
    "],\n",
    "\"Malignant, pre-malignant or other related conditions or risk factors?\": {\n",
    "    \"value\": \"\",           # Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Malignant, pre-malignant or other related conditions or risk factors details\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; include diagnosis, dates, doctors, source info\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Medical history that would have increased the risk of cancer\": {\n",
    "    \"value\": \"\",           # Nature of illness, date of diagnosis, source of info\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Family history that would have increased the risk of Cancer\": {\n",
    "    \"value\": \"\",           # Relationship, nature of illness, date, source\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Smoking habits\": {\n",
    "    \"value\": \"\",           # Past and present, duration, # cigarettes/day, source of info\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Alcohol consumption habits\": {\n",
    "    \"value\": \"\",           # Type, amount/day, duration, source of info\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Is the tumour or cancer in any way caused directly or indirectly by alcohol or drug abuse?\": {\n",
    "    \"value\": \"\",           # Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Alcohol/drug abuse details\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; copy verbatim if present\n",
    "    \"confidence\": 0.0\n",
    "}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "NTUC_FIELD_JSON_WITH_INLINE_5 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "\"Tumour caused by HIV or AIDS?\": {\n",
    "    \"value\": \"\",           # Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"HIV antibody status\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; leave blank if \"No\" or unknown\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"HIV/AIDS diagnosis date (dd/mm/yyyy)\": {\n",
    "    \"value\": \"\",           # Only if previous == \"Yes\"; keep original date format\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Any other significant health conditions\": {\n",
    "    \"value\": \"\",           # Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "    \"confidence\": 0.0\n",
    "},\n",
    "\"Details of other health conditions (rows 0..3)\": [\n",
    "    # Rules:\n",
    "    # - If no health conditions → return []\n",
    "    # - If conditions exist → return 1..3 row objects (as many as are clearly present, capped at 3)\n",
    "    {\n",
    "        \"Diagnosis\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Name of doctor\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Name/address of clinic/hospital\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Date of diagnosis (dd/mm/yyyy)\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Duration of condition\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        },\n",
    "        \"Treatment received\": {\n",
    "            \"value\": \"\",\n",
    "            \"confidence\": 0.0\n",
    "        }\n",
    "    }\n",
    "    # Add a second/third object ONLY if multiple conditions are clearly present\n",
    "]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4ofXaaNNbiM"
   },
   "outputs": [],
   "source": [
    "NTUC_FIELD_JSON_SCHEMAS = {\n",
    "    1: NTUC_FIELD_JSON_WITH_INLINE_1,\n",
    "    2: NTUC_FIELD_JSON_WITH_INLINE_2,\n",
    "    3: NTUC_FIELD_JSON_WITH_INLINE_3,\n",
    "    4: NTUC_FIELD_JSON_WITH_INLINE_4,\n",
    "    5: NTUC_FIELD_JSON_WITH_INLINE_5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HaBzf8xNGHX"
   },
   "source": [
    "## GE META PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0fK-E0YNNRL"
   },
   "outputs": [],
   "source": [
    "GE_FIELD_JSON_WITH_INLINE_1 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "    \"Date when insured first consulted you for cancer (ddmmyyyy)\": {\n",
    "        \"value\": \"\",                // Find the EARLIEST \"Visit/Appointment Date\" or \"Authored:\" date\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "\n",
    "    \"Please state symptoms presented and date symptoms first appeared (rows 0..3)\": [\n",
    "        // Rules:\n",
    "        // - If no symptoms are stated → return [].\n",
    "        // - If exactly one symptom is stated → return ONE object (length = 1).\n",
    "        // - If three or more symptoms are stated → return THREE objects (take the first three).\n",
    "        // - Keep date strings exactly as in the notes; do not reformat.\n",
    "        {\n",
    "            \"Symptom\": {\n",
    "              // CRITICAL: Initial symptom that led to the diagnosis.\n",
    "              // DO NOT extract treatment side effects (e.g., \"nausea\", \"mucositis\", \"rash\") that appear after a treatment is mentioned.\n",
    "                \"value\": \"\",\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"Duration of symptom\": {\n",
    "                \"value\": \"\",               // Copy duration associated with this symptom\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"Date symptoms first started (dd/mm/yyyy)\": {\n",
    "                \"value\": \"\",               // Keep date text as-is\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "        }\n",
    "        // Add a second object ONLY if multiple distinct symptoms are clearly present\n",
    "    ],\n",
    "\n",
    "    \"Source of above information\": {\n",
    "        \"value\": \"\",                // State the source. Allowed: \"Patient\" / \"Referring Doctor\" / \"Others\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "\n",
    "    \"What is the source of the above information? If Referring Doctor / Others, specify name & address (rows 0..2)\": [\n",
    "        // Rules:\n",
    "        // - If no referring doctors or Others are stated → return [].\n",
    "        // - If one referring doctor is stated → return ONE object (length = 1).\n",
    "        // - If two or more are stated → return up to TWO objects (take the first two).\n",
    "        {\n",
    "            \"Name\": {\n",
    "                \"value\": \"\",               // Name of the referring doctor.\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"Address\": {\n",
    "                \"value\": \"\",               // Address of the referring doctor.\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "      }\n",
    "      // Add a second and third object ONLY if there are multiple disticnt sources to capture.\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"Date when Cancer was FIRST diagnosed (DD/MM/YYYY)\": {\n",
    "        \"value\": \"\",                // Date of initial cancer diagnosis. Format as DD/MM/YYYY.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Diagnosis was first made by (name of Doctor)\": {\n",
    "        \"value\": \"\",                // Name of the doctor who made the initial diagnosis.\n",
    "        \"confidence\": 0.0\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "GE_FIELD_JSON_WITH_INLINE_2 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "    \"Actual diagnosis\": {\n",
    "        \"value\": \"\",                // State the final medical diagnosis from the diagnosis summary\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Date when insured first became aware of this illness (ddmmyyyy)\": {\n",
    "        \"value\": \"\",                // Date patient was first aware of the illness.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "\n",
    "    \"Was the illness suffered by Life Assured caused directly or indirectly by alcohol or drug abuse?\": {\n",
    "        \"value\": \"\",                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "\n",
    "    \"If illness caused directly or indirectly by alcohol or drug abuse, please give details\": {\n",
    "        \"value\": \"\",                // Only if previous == \"Yes\"; include details\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"What is the staging of the tumour?\": {\n",
    "        \"value\": \"\",                // e.g., Stage II, Stage IV.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Please state the tumour classification (eg TMN classification etc)\": {\n",
    "        \"value\": \"\",                // Extract the TNM code (e.g., \"pT2NO\", \"T1cN0M0\").\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Was the cancer completely localised?\": {\n",
    "        \"value\": \"\",               //\"Yes\" if staging is N0 AND M0. \"No\" if N is 1+ OR M is 1+.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Was there invasion of tissues?\": {\n",
    "        \"value\":\"\",                // \"Yes\" if staging is T4\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Were regional lymph nodes involved?\": {\n",
    "        \"value\": \"\",                // \"N0\" means \"No\". \"N1\" or \"N2\" means \"Yes\".\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Were there distant metastases?\": {\n",
    "        \"value\": \"\"                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Did the Life Assured undergo any surgery?\": {\n",
    "        \"value\": \"\",                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Date of surgery (ddmmyyyy)\": {\n",
    "        \"value\": \"\",                // Only if previous == \"Yes\"; keep original date format\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Surgical procedure performed\": {\n",
    "        \"value\": \"\",                // If yes, name of the surgical procedure.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Was there any other mode of treatment, other than surgery, which could be undertaken to treat the Life Assured’s condition?\": {\n",
    "        \"value\": \"\",                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Type of treatment other than surgery that could be undertaken to treat condition\": {\n",
    "        \"value\": \"\",               // Only if previous == \"Yes\";\n",
    "        \"confidence\": 0.0\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "GE_FIELD_JSON_WITH_INLINE_3 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "\n",
    "    \"Has the Life Assured underwent other mode of treatment?\": {\n",
    "        \"value\": \"\",                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "\n",
    "    \"Date of other treatment (ddmmyyyy)\": {\n",
    "        \"value\": \"\",                // Only if previous == \"Yes\"; keep original date format\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Reason for no other mode of treatment\": {\n",
    "        \"value\": \"\",                // If no other mode of treatment, provide reason\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"What other forms of treatment did the Life Assured undergo (eg chemotherapy, radiotherapy etc)?\": {\n",
    "        \"value\": \"\",                // List other treatments like chemotherapy, radiotherapy.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"If diagnosis is leukaemia, please provide the type of leukaemia\": {\n",
    "        \"value\": \"\",                // Specify type, e.g., AML, CML.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"If the diagnosis is malignant melanoma, please give full details of size, thickness (Breslow classification) and/or depth of invasion (Clark level)\": {\n",
    "        \"value\": \"\",                // Provide specifics for melanoma, e.g., \"Breslow 0.5mm, Clark Level II\".\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Is the diagnosis related to Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)?\": {\n",
    "        \"value\": \"\",                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Date of diagnosis for HIV/AIDS (ddmmyyyy)\": {\n",
    "        \"value\": \"\",                // Only if previous == \"Yes\"; keep original date format\n",
    "        \"confidence\": 0.0\n",
    "    }\n",
    "    \"Life Assured’s mental and cognitive abiliites\": {\n",
    "        \"value\": \"\",                // Summary of patient's mental/cognitive state.\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Is Life Assured mentally capable?\": {\n",
    "        \"value\": \"\",                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "GE_FIELD_JSON_WITH_INLINE_4 = \"\"\"\n",
    "FIELD JSON WITH INLINE META (guidance in comments — DO NOT return comments):\n",
    "\n",
    "{\n",
    "    \"Does Life Assured have any other medical conditions?\": {\n",
    "        \"value\": \"\",                // Check \"PMHx\" or \"Other Med History\". \"nil\" = \"No\". \"HTN\" etc. = \"Yes\".\n",
    "        \"confidence\": 0.0\n",
    "    }\n",
    "\n",
    "    \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3)\": [\n",
    "        // Rules:\n",
    "        // - If no other conditions are stated → return [].\n",
    "        // - If one other condition is stated → return ONE object (length = 1).\n",
    "        // - If three or more are stated → return up to THREE objects (take the first three).\n",
    "        {\n",
    "            \"Medical condition\": {\n",
    "                \"value\": \"\",\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"Diagnosis date (dd/mm/yyyy)\": {\n",
    "                \"value\": \"\",\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"Name & address of treating doctor\": {\n",
    "                \"value\": \"\",\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "        }\n",
    "        // Add a second and third object ONLY if there are multiple distinct medical conditions\n",
    "    ],\n",
    "\n",
    "    \"Does Life Assured have any family history?\": {\n",
    "        \"value\": \"\",                // Allowed: \"Yes\" / \"No\" / \"\" (unknown)\n",
    "        \"confidence\": 0.0\n",
    "    }\n",
    "\n",
    "    \"Family History (rows 0..3)\": [\n",
    "        // Rules:\n",
    "        // - If no family history is stated → return [].\n",
    "        // - If one family member is stated → return ONE object (length = 1).\n",
    "        // - If two or more are stated → return up to THREE objects (take the first three).\n",
    "        {\n",
    "            \"Relationship to Life Assured\": {\n",
    "                \"value\": \"\",\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"Family history condition\": {\n",
    "                \"value\": \"\",\n",
    "                \"confidence\": 0.0\n",
    "            },\n",
    "            \"Age of onset\": {\n",
    "                \"value\": \"\",\n",
    "                \"confidence\": 0.0\n",
    "            }\n",
    "        }\n",
    "        // Add a second and third object ONLY if there are multiple distinct family history\n",
    "    ],\n",
    "    \"Details of the Life Assured’s habits in relation to cigarette smoking, including the duration of smoking habit, number of cigarettes smoked per day and source of information\": {\n",
    "        \"value\": \"\",                // e.g., \"Smoker, 10 years, 1 pack/day\" or \"Non-smoker\".\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Details of the Life Assured’s habit in relation to alcohol consumption including the amount of alcohol consumption per day and source of information\": {\n",
    "        \"value\": \"\",                // e.g., \"Social drinker, 2-3 units/week\" or \"No alcohol consumption\".\n",
    "        \"confidence\": 0.0\n",
    "    },\n",
    "    \"Please provide any other information which may be of assistance to us in assessing this claim\": {\n",
    "        \"value\": \"\",                // Any other relevant medical notes or summary.\n",
    "        \"confidence\": 0.0\n",
    "    }\n",
    "\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ex2vz6xsNevR"
   },
   "outputs": [],
   "source": [
    "GE_FIELD_JSON_SCHEMAS = {\n",
    "    1: GE_FIELD_JSON_WITH_INLINE_1,\n",
    "    2: GE_FIELD_JSON_WITH_INLINE_2,\n",
    "    3: GE_FIELD_JSON_WITH_INLINE_3,\n",
    "    4: GE_FIELD_JSON_WITH_INLINE_4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1WuV_N5NN7e"
   },
   "source": [
    "## BUILD PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jhgMGmr8m2F"
   },
   "outputs": [],
   "source": [
    "# NTUC_FIELD_JSON_SCHEMAS\n",
    "# GE_FIELD_JSON_SCHEMAS\n",
    "\n",
    "def build_prompt(i_txt: str, page_num: int, field_json_schemas: dict):\n",
    "  system = META_RULES.strip()\n",
    "  schema = field_json_schemas.get(page_num, \"\")\n",
    "\n",
    "  user = f\"\"\"\n",
    "You are given the retrieval results from RAG, where it details the most relevant sections of doctor's records for a specific patient in Singapore. They are excerpts from different sections found in the appointment notes with relevant dates and information:\n",
    "RETRIREVED TEXT:\n",
    "<<<\n",
    "{i_txt}\n",
    ">>>\n",
    "\n",
    "\n",
    "Task:\n",
    "- Fill the JSON schema below using ONLY information from the notes, and also include the confidence score which should reflect probability that YOUR answer is correct\n",
    "- If no information exists, output \"\".\n",
    "- Try your best to fill in the JSON as completely as possible, even if it is not accurate, you may score it a low confidence score.\n",
    "- Return JSON only.\n",
    "\n",
    "Remember, return ONLY valid JSON. DO NOT include markdown, comments, or explanations. No comments at all.\n",
    "\n",
    "JSON schema:\n",
    "{schema}\n",
    "\"\"\".strip()\n",
    "\n",
    "  return system + \"\\n\" + user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Peh6QLM_NGPX"
   },
   "source": [
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucJT-_fuOJ0C"
   },
   "source": [
    "## Clean LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KikLvzUvOMeL"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def process_llm_output(input_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Cleans an LLM output text file and converts it into a single flattened JSON file.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): raw LLM text.\n",
    "\n",
    "    Returns:\n",
    "        dict: The merged and flattened JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def clean_llm_output(text: str) -> str:\n",
    "        text = re.sub(r\"--- Page \\d+ ---\", \"\", text)\n",
    "        text = re.sub(r\"```json\", \"\", text)\n",
    "        text = re.sub(r\"```\", \"\", text)\n",
    "\n",
    "        def _strip_comments(match):\n",
    "            s = match.group(0)\n",
    "            if s.startswith('\"'):\n",
    "                return s\n",
    "            return re.sub(r\"//.*\", \"\", s)\n",
    "\n",
    "        text = re.sub(r'\"(?:\\\\.|[^\"\\\\])*\"|[^\"\\n]+', _strip_comments, text)\n",
    "        text = re.sub(r\",\\s*([}\\]])\", r\"\\1\", text)\n",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\", text)\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_json_objects(text: str):\n",
    "        objs = []\n",
    "        n = len(text)\n",
    "        i = 0\n",
    "        in_str = False\n",
    "        escape = False\n",
    "        depth = 0\n",
    "        start = None\n",
    "        while i < n:\n",
    "            ch = text[i]\n",
    "            if ch == '\"' and not escape:\n",
    "                in_str = not in_str\n",
    "            if not in_str:\n",
    "                if ch == '{':\n",
    "                    if depth == 0:\n",
    "                        start = i\n",
    "                    depth += 1\n",
    "                elif ch == '}':\n",
    "                    depth -= 1\n",
    "                    if depth == 0 and start is not None:\n",
    "                        objs.append(text[start:i+1])\n",
    "                        start = None\n",
    "            if ch == \"\\\\\" and not escape:\n",
    "                escape = True\n",
    "            else:\n",
    "                escape = False\n",
    "            i += 1\n",
    "        if start is not None:\n",
    "            tail = text[start:]\n",
    "            opens = tail.count('{') - tail.count('}')\n",
    "            opens_sq = tail.count('[') - tail.count(']')\n",
    "            tail_fixed = tail + ('}' * opens) + (']' * opens_sq)\n",
    "            objs.append(tail_fixed)\n",
    "        return objs\n",
    "\n",
    "    def repair_json(s: str) -> str:\n",
    "        s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
    "        open_curly = s.count('{') - s.count('}')\n",
    "        open_sq = s.count('[') - s.count(']')\n",
    "        if open_curly > 0:\n",
    "            s += '}' * open_curly\n",
    "        if open_sq > 0:\n",
    "            s += ']' * open_sq\n",
    "        return s\n",
    "\n",
    "    def flatten_json(obj: dict, parent_key: str = \"\", sep: str = \" \") -> dict:\n",
    "        items = {}\n",
    "        for k, v in obj.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\".strip()\n",
    "            if isinstance(v, dict):\n",
    "                items.update(flatten_json(v, new_key, sep=sep))\n",
    "            elif isinstance(v, list):\n",
    "                for idx, elem in enumerate(v, 1):\n",
    "                    if isinstance(elem, dict):\n",
    "                        items.update(flatten_json(elem, f\"{new_key} ({idx})\", sep=sep))\n",
    "                    else:\n",
    "                        items[f\"{new_key} ({idx})\"] = elem\n",
    "            else:\n",
    "                items[new_key] = v\n",
    "        return items\n",
    "\n",
    "    def fix_short_dates(data: dict) -> dict:\n",
    "        \"\"\"Detect and fix ddmmyy-style date strings by expanding to ddmmyyyy.\"\"\"\n",
    "        fixed = {}\n",
    "        for k, v in data.items():\n",
    "            if isinstance(v, str):\n",
    "                # match exactly 6 digits (e.g., '101025' -> '10/10/25' style)\n",
    "                if re.fullmatch(r\"\\d{6}\", v):\n",
    "                    dd, mm, yy = v[:2], v[2:4], v[4:]\n",
    "                    v = f\"{dd}{mm}20{yy}\"  # add '20' before the year part\n",
    "                # 'dd/mm/yy' format\n",
    "                elif re.fullmatch(r\"\\d{2}/\\d{2}/\\d{2}\", v):\n",
    "                    dd, mm, yy = v.split(\"/\")\n",
    "                    v = f\"{dd}/{mm}/20{yy}\"\n",
    "            fixed[k] = v\n",
    "        return fixed\n",
    "    # --- Read + clean ---\n",
    "    cleaned = clean_llm_output(input_text)\n",
    "    json_chunks = extract_json_objects(cleaned)\n",
    "\n",
    "    merged = {}\n",
    "    all_keys = set()\n",
    "\n",
    "    for i, chunk in enumerate(json_chunks, 1):\n",
    "        fixed = repair_json(chunk)\n",
    "        try:\n",
    "            obj = json.loads(fixed)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                first = fixed.find('{')\n",
    "                last = fixed.rfind('}')\n",
    "                if first != -1 and last != -1 and last > first:\n",
    "                    candidate = repair_json(fixed[first:last+1])\n",
    "                    obj = json.loads(candidate)\n",
    "                else:\n",
    "                    continue\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        flat = flatten_json(obj)\n",
    "        merged.update(flat)\n",
    "        all_keys.update(flat.keys())\n",
    "\n",
    "    merged = fix_short_dates(merged)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYBnqoMVOOnV"
   },
   "source": [
    "## Utilities for Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdsUBUy7OQMh"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def split_date(date_str):\n",
    "    \"\"\"Split various date formats into (dd, mm, yyyy).\"\"\"\n",
    "    if not date_str:\n",
    "        return \"\", \"\", \"\"\n",
    "    # dd/mm/yyyy\n",
    "    m = re.match(r\"(\\d{2})/(\\d{2})/(\\d{4})\", date_str)\n",
    "    if m:\n",
    "        return m.group(1), m.group(2), m.group(3)\n",
    "    # yyyy-mm-dd\n",
    "    m = re.match(r\"(\\d{4})-(\\d{2})-(\\d{2})\", date_str)\n",
    "    if m:\n",
    "        return m.group(3), m.group(2), m.group(1)\n",
    "    # dd-mmm-yyyy\n",
    "    m = re.match(r\"(\\d{2})-([A-Za-z]{3})-(\\d{4})\", date_str)\n",
    "    if m:\n",
    "        cal = {\n",
    "            \"Jan\": \"01\",\n",
    "            \"Feb\": \"02\",\n",
    "            \"Mar\": \"03\",\n",
    "            \"Apr\": \"04\",\n",
    "            \"May\": \"05\",\n",
    "            \"Jun\": \"06\",\n",
    "            \"Jul\": \"07\",\n",
    "            \"Aug\": \"08\",\n",
    "            \"Sep\": \"09\",\n",
    "            \"Oct\": \"10\",\n",
    "            \"Nov\": \"11\",\n",
    "            \"Dec\": \"12\"\n",
    "        }\n",
    "        month = m.group(2)\n",
    "        month_num = cal.get(month)\n",
    "        return m.group(1), month_num, m.group(3)\n",
    "    # ddmmyy\n",
    "    m = re.match(r\"(\\d{2})-(\\d{2})-(\\d{2})\", date_str)\n",
    "    if m:\n",
    "        year = m.group(3)\n",
    "        new_year = \"20\" + year\n",
    "        return m.group(1), m.group(2), new_year\n",
    "    # fallback\n",
    "    return date_str, \"\", \"\"\n",
    "\n",
    "def set_field_with_confidence(field, combined, key_base):\n",
    "    \"\"\"Set value + confidence for text fields.\"\"\"\n",
    "    value = combined.get(f\"{key_base} value\", \"\")\n",
    "    confidence = combined.get(f\"{key_base} confidence\", \"\")\n",
    "    field[\"field_value\"] = value\n",
    "    field[\"confidence\"] = str(confidence) if confidence != \"\" else \"\"\n",
    "\n",
    "\n",
    "def set_date_with_confidence(field, combined, key_base, name):\n",
    "    \"\"\"Set dd/mm/yyyy split fields with confidence.\"\"\"\n",
    "    date_str = combined.get(f\"{key_base} value\", \"\")\n",
    "    confidence = combined.get(f\"{key_base} confidence\", \"\")\n",
    "    dd, mm, yyyy = split_date(date_str)\n",
    "\n",
    "    if \"(dd)\" in name:\n",
    "        field[\"field_value\"] = dd\n",
    "    elif \"(mm)\" in name:\n",
    "        field[\"field_value\"] = mm\n",
    "    elif \"(yyyy)\" in name:\n",
    "        field[\"field_value\"] = yyyy\n",
    "\n",
    "    field[\"confidence\"] = str(confidence) if confidence != \"\" else \"\"\n",
    "\n",
    "\n",
    "def set_checkbox_with_confidence(field, combined, key_base):\n",
    "    \"\"\"Set Yes/No checkboxes with confidence.\"\"\"\n",
    "    value = combined.get(f\"{key_base} value\", \"\")\n",
    "    confidence = combined.get(f\"{key_base} confidence\", \"\")\n",
    "\n",
    "    if \"Yes\" in field[\"field_name\"] and value == \"Yes\":\n",
    "        field[\"field_value\"] = \"Yes\"\n",
    "    elif \"No\" in field[\"field_name\"] and value == \"No\":\n",
    "        field[\"field_value\"] = \"Yes\"\n",
    "    else:\n",
    "        field[\"field_value\"] = \"\"\n",
    "\n",
    "    field[\"confidence\"] = str(confidence) if confidence != \"\" else \"\"\n",
    "\n",
    "def set_delete_with_confidence(field, combined, key_base):\n",
    "    \"\"\"Set Yes/No delete fields with confidence.\"\"\"\n",
    "    value = combined.get(f\"{key_base} value\", \"\")\n",
    "    confidence = combined.get(f\"{key_base} confidence\", \"\")\n",
    "\n",
    "    if \"Yes\" in field[\"field_name\"] and value == \"No\":\n",
    "        field[\"field_value\"] = \"X\"\n",
    "    elif \"No\" in field[\"field_name\"] and value == \"Yes\":\n",
    "        field[\"field_value\"] = \"X\"\n",
    "    else:\n",
    "        field[\"field_value\"] = \"\"\n",
    "\n",
    "    field[\"confidence\"] = str(confidence) if confidence != \"\" else \"\"\n",
    "\n",
    "# only for GE form, where unique field needs to be deleted\n",
    "def set_source_with_confidence(field, combined, key_base):\n",
    "    \"\"\"Set Yes/No delete fields with confidence.\"\"\"\n",
    "    value = combined.get(f\"{key_base} value\", \"\")\n",
    "    confidence = combined.get(f\"{key_base} confidence\", \"\")\n",
    "\n",
    "    field_name = field[\"field_name\"]\n",
    "\n",
    "    # Case 1: If the selected value is \"Patient\"\n",
    "    if value == \"Patient\":\n",
    "        if \"Referring Doctor\" in field_name or \"Others\" in field_name:\n",
    "            field[\"field_value\"] = \"X\"\n",
    "        elif \"Patient\" in field_name:\n",
    "            field[\"field_value\"] = \"\"\n",
    "        else:\n",
    "            field[\"field_value\"] = \"\"\n",
    "\n",
    "    # Case 2: If the selected value is \"Referring Doctor\"\n",
    "    elif value == \"Referring Doctor\":\n",
    "        if \"Patient\" in field_name or \"Others\" in field_name:\n",
    "            field[\"field_value\"] = \"X\"\n",
    "        elif \"Referring Doctor\" in field_name:\n",
    "            field[\"field_value\"] = \"\"\n",
    "        else:\n",
    "            field[\"field_value\"] = \"\"\n",
    "\n",
    "    # Case 3: If the selected value is \"Others\"\n",
    "    elif value == \"Others\":\n",
    "        if \"Patient\" in field_name or \"Referring Doctor\" in field_name:\n",
    "            field[\"field_value\"] = \"X\"\n",
    "        elif \"Others\" in field_name:\n",
    "            field[\"field_value\"] = \"\"\n",
    "        else:\n",
    "            field[\"field_value\"] = \"\"\n",
    "\n",
    "    # Default\n",
    "    else:\n",
    "        field[\"field_value\"] = \"\"\n",
    "\n",
    "    # Set confidence if present\n",
    "    field[\"confidence\"] = str(confidence) if confidence != \"\" else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eAkWMjBOUE2"
   },
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDIS63thOVU7"
   },
   "source": [
    "### MAPPER - NTUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcAK3pV3OWc_"
   },
   "outputs": [],
   "source": [
    "def map_combined_to_fields_income(combined, form_fields):\n",
    "    for field in form_fields[\"fields\"]:\n",
    "        name = field[\"field_name\"]\n",
    "\n",
    "        # --- Doctors/hospitals consulted (explicit mappings) ---\n",
    "        if \"Please provide the date(s) of consultations at listed clinics/hospitals to which the Insured has attended for this condition (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (1) Date(s) of consultation (dd/mm/yyyy)\")\n",
    "        elif \"Please provide the name of doctor(s) which the Insured has been referred to for this condition (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (1) Name of doctor\")\n",
    "        elif \"Please provide the name and address of clinics/hospitals to which the Insured has attended for this condition (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (1) Name and Address of Clinic/Hospital\")\n",
    "        elif \"Please provide details of diagnosis made during the consultation(s) at listed clinics/hospitals to which the Insured has attended for this condition (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (1) Diagnosis made\")\n",
    "\n",
    "        if \"Please provide the date(s) of consultations at listed clinics/hospitals to which the Insured has attended for this condition (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (2) Date(s) of consultation (dd/mm/yyyy)\")\n",
    "        elif \"Please provide the name of doctor(s) which the Insured has been referred to for this condition (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (2) Name of doctor\")\n",
    "        elif \"Please provide the name and address of clinics/hospitals to which the Insured has attended for this condition (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (2) Name and Address of Clinic/Hospital\")\n",
    "        elif \"Please provide details of diagnosis made during the consultation(s) at listed clinics/hospitals to which the Insured has attended for this condition (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (2) Diagnosis made\")\n",
    "\n",
    "        if \"Please provide the date(s) of consultations at listed clinics/hospitals to which the Insured has attended for this condition (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (3) Date(s) of consultation (dd/mm/yyyy)\")\n",
    "        elif \"Please provide the name of doctor(s) which the Insured has been referred to for this condition (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (3) Name of doctor\")\n",
    "        elif \"Please provide the name and address of clinics/hospitals to which the Insured has attended for this condition (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (3) Name and Address of Clinic/Hospital\")\n",
    "        elif \"Please provide details of diagnosis made during the consultation(s) at listed clinics/hospitals to which the Insured has attended for this condition (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctors/hospitals consulted for this condition (rows 0..3) (3) Diagnosis made\")\n",
    "\n",
    "        elif \"Has the Insured ever had any malignant, pre-malignant or other related conditions or risk factors? If “Yes”, please provide details, including diagnosis, date of diagnosis, dates of consultation, name and address of doctor/ clinic and source of information\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Malignant, pre-malignant or other related conditions or risk factors details\")\n",
    "        elif \"Has the Insured ever had any malignant, pre-malignant or other related conditions or risk factors?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Malignant, pre-malignant or other related conditions or risk factors?\")\n",
    "\n",
    "        # --- Period of records ---\n",
    "        elif \"Over what period do your records extend? Start date\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Over what period do your records extend? Start date (dd/mm/yyyy)\", name)\n",
    "\n",
    "        elif \"Over what period do your records extend? End date\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Over what period do your records extend? End date (dd/mm/yyyy)\", name)\n",
    "\n",
    "        # --- First consultation ---\n",
    "        elif \"When did the Insured first consult you\" in name:\n",
    "            set_date_with_confidence(field, combined, \"When did the Insured first consult you for this condition? (dd/mm/yyyy)\", name)\n",
    "\n",
    "        elif \"duration of symptoms\" in name and \"(1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"When you first saw the Insured, what were the symptoms presented and their duration? (rows 0..2) (1) Duration of symptom\")\n",
    "\n",
    "        elif \"date of onset\" in name and \"(1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"When you first saw the Insured, what were the symptoms presented and their duration? (rows 0..2) (1) Date of onset (dd/mm/yyyy)\")\n",
    "\n",
    "        elif \"symptoms presented\" in name and \"(1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"When you first saw the Insured, what were the symptoms presented and their duration? (rows 0..2) (1) Symptom presented\")\n",
    "\n",
    "        elif \"duration of symptoms\" in name and \"(2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"When you first saw the Insured, what were the symptoms presented and their duration? (rows 0..2) (2) Duration of symptom\")\n",
    "\n",
    "        elif \"date of onset\" in name and \"(2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"When you first saw the Insured, what were the symptoms presented and their duration? (rows 0..2) (2) Date of onset (dd/mm/yyyy)\")\n",
    "\n",
    "        elif \"symptoms presented\" in name and \"(2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"When you first saw the Insured, what were the symptoms presented and their duration? (rows 0..2) (2) Symptom presented\")\n",
    "\n",
    "        # --- Other doctors consulted ---\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Name of Doctor (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (1) Name of doctor\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and  \"clinic / hospital (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (1) Name and address of clinic / hospital\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Date(s) of consultation (dd/mm/yyyy) (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (1) Date(s) of consultation (dd/mm/yyyy)\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Diagnosis made (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (1) Diagnosis made\")\n",
    "\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Name of Doctor (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (2) Name of doctor\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and  \"clinic / hospital (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (2) Name and address of clinic / hospital\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Date(s) of consultation (dd/mm/yyyy) (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (2) Date(s) of consultation (dd/mm/yyyy)\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Diagnosis made (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (2) Diagnosis made\")\n",
    "\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Name of Doctor (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (3) Name of doctor\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and  \"clinic / hospital (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (3) Name and address of clinic / hospital\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Date(s) of consultation (dd/mm/yyyy) (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (3) Date(s) of consultation (dd/mm/yyyy)\")\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you? If “Yes”,\" and \"Diagnosis made (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other doctors consulted (rows 0..3) (3) Diagnosis made\")\n",
    "\n",
    "        elif \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Did the Insured consult any other doctors for this illness or its symptoms before he/she consulted you?\")\n",
    "\n",
    "        # --- Histological diagnosis ---\n",
    "        elif \"histological diagnosis\" in name.lower():\n",
    "            set_field_with_confidence(field, combined, \"Histological diagnosis\")\n",
    "\n",
    "        elif \"Date of diagnosis (dd/mm/yyyy):\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Date of diagnosis (dd/mm/yyyy)\", name)\n",
    "\n",
    "        elif \"where the diagnosis was first made\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Doctor/clinic where diagnosis was first made\")\n",
    "\n",
    "        elif \"when the Insured was first informed of the diagnosis\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Date Insured was first informed of diagnosis (dd/mm/yyyy)\", name)\n",
    "\n",
    "        # --- Biopsy ---\n",
    "        elif \"date of biopsy\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Biopsy date (dd/mm/yyyy)\", name)\n",
    "        elif \"Was a biopsy of the tumour performed? If “No”, please state why and how the diagnosis was confirmed\" in name:\n",
    "            set_field_with_confidence(field, combined, \"If No, how was the diagnosis confirmed?\")\n",
    "        elif \"Was a biopsy of the tumour performed?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Was a biopsy of the tumour performed?\")\n",
    "\n",
    "        # --- Tumour details ---\n",
    "        elif \"site or organ involved\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Site or organ involved\")\n",
    "\n",
    "        elif \"is the staging of the tumour?\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Staging\")\n",
    "\n",
    "        elif \"Has the cancer spread\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Has the cancer spread beyond the layer of cells?\")\n",
    "        elif \"Was the disease completely localised\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Was the disease completely localised?\")\n",
    "        elif \"Was there invasion of adjacent tissues\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Was there invasion of adjacent tissues?\")\n",
    "        elif \"Were regional lymph nodes involved\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Were regional lymph nodes involved?\")\n",
    "        elif \"Were there distant metastases? If “Yes”, please provide full details, including site of any metastases, etc\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Metastases details\")\n",
    "        elif \"Were there distant metastases\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Were there distant metastases?\")\n",
    "\n",
    "        # --- Special conditions (CIS, premalignant, etc.) ---\n",
    "        elif \"Is the condition carcinoma-in-situ?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Is the condition carcinoma-in-situ?\")\n",
    "        elif \"Is the condition pre-malignant or non-invasive?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Pre-malignant / non-invasive\")\n",
    "        elif \"borderline malignancy\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Borderline / suspicious malignancy\")\n",
    "        elif \"Cervical Dysplasia\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Cervical dysplasia CIN1-3 (without CIS)\")\n",
    "\n",
    "        elif \"Carcinoma-in-situ of the Biliary\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Carcinoma-in-situ of biliary system\")\n",
    "        elif \"Hyperkeratoses\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Hyperkeratoses, basal/squamous skin cancers\")\n",
    "        elif \"Bladder Cancer\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Bladder cancer T1N0M0 or below\")\n",
    "        elif \"Papillary Micro-carcinoma of the Bladder\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Bladder papillary micro-carcinoma\")\n",
    "\n",
    "        elif \"Prostate cancer\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Is Prostate cancer T1N0M0, T1, or a equivalent or lesser classification?\")\n",
    "        elif \"Thyroid Cancer\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Is Thyriod cancer T1N0M0 or below?\")\n",
    "        elif \"size in diameter (cm)\" in name and \"Thyroid\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Thyriod diameter\")\n",
    "\n",
    "        elif \"Papillary Micro-carcinoma of the Thyroid\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Is Thyroid papillary micro-carcinoma?\")\n",
    "        elif \"size in diameter (cm)\" in name and \"Papillary Micro-carcinoma\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Thyroid papillary micro-carcinoma size\")\n",
    "\n",
    "        # --- Leukaemia / Melanoma / GIST ---\n",
    "        elif \"If the diagnosis is leukaemia, please state type of leukaemia\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Leukaemia type\")\n",
    "        elif \"If the diagnosis is leukaemia, please state type of RAI staging\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Leukaemia RAI staging\")\n",
    "        elif \"malignant melanoma\" in name and \"Breslow\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Melanoma size/thickness (Breslow mm)\")\n",
    "        elif \"malignant melanoma\" in name and \"Clark\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Melanoma Clark level\")\n",
    "        elif \"Has the condition caused invasion beyond the epidermis\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Has the condition caused invasion beyond the epidermis?\")\n",
    "        elif \"GIST\" in name and \"classification\" in name:\n",
    "            set_field_with_confidence(field, combined, \"GIST TNM classification\")\n",
    "        elif \"GIST\" in name and \"Mitotic\" in name:\n",
    "            set_field_with_confidence(field, combined, \"GIST mitotic count (HPF)\")\n",
    "\n",
    "        # --- Treatments ---\n",
    "\n",
    "        elif \"Please provide full details of all type of treatment provided (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (1) Treatment type\")\n",
    "        elif \"Please provide full details of date of treatment provided (dd/mm/yyyy) (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (1) Date of treatment (dd/mm/yyyy)\")\n",
    "        elif \"Please provide full details of duration of treatment provided (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (1) Duration of treatment\")\n",
    "\n",
    "        elif \"Please provide full details of all type of treatment provided (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (2) Treatment type\")\n",
    "        elif \"Please provide full details of date of treatment provided (dd/mm/yyyy) (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (2) Date of treatment (dd/mm/yyyy)\")\n",
    "        elif \"Please provide full details of duration of treatment provided (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (2) Duration of treatment\")\n",
    "\n",
    "        elif \"Please provide full details of all type of treatment provided (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (3) Treatment type\")\n",
    "        elif \"Please provide full details of date of treatment provided (dd/mm/yyyy) (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (3) Date of treatment (dd/mm/yyyy)\")\n",
    "        elif \"Please provide full details of duration of treatment provided (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Has the patient received treatment for this illness? (rows 0..3) (3) Duration of treatment\")\n",
    "\n",
    "        # --- Active treatment rejection ---\n",
    "        elif \"Has active treatment and therapy\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Has active treatment and therapy been rejected in favour of symptoms relief\")\n",
    "        elif \"Active treatment rejection reason\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Active treatment rejection reason\")\n",
    "\n",
    "        # --- Surgeries ---\n",
    "        elif \"Was radical surgery (total and complete removal of the affected organ) done? If “Yes”, please state the name of the surgery, surgical code/table\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Radical surgery code/table\")\n",
    "        elif \"Was radical surgery (total and complete removal of the affected organ) done? If “Yes”, please state the date surgery was performed\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Radical surgery date (dd/mm/yyyy)\", name)\n",
    "        elif \"Was radical surgery (total and complete removal of the affected organ) done?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Was radical surgery done?\")\n",
    "\n",
    "        elif \"For mastectomy cases, was reconstructive surgery done or recommended? If “Yes”, please state date surgery was performed\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Reconstructive surgery date (dd/mm/yyyy)\", name)\n",
    "        elif \"For mastectomy cases, was reconstructive surgery done or recommended?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"For mastectomy cases, was reconstructive surgery done or recommended?\")\n",
    "\n",
    "        elif \"reconstructive surgery\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Reconstructive surgery date (dd/mm/yyyy)\", name)\n",
    "\n",
    "        # --- Follow-up / Discharge ---\n",
    "        elif \"Is the Insured still on follow-up at your clinic? If “Yes”, please provide state date of next appointment (dd/mm/yyyy)\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Next appointment date (dd/mm/yyyy)\", name)\n",
    "        elif \"Is the Insured still on follow-up at your clinic? If \\\"No”, please provide date of discharge (dd/mm/yyyy)\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Discharge date (dd/mm/yyyy)\", name)\n",
    "        elif \"Is the Insured still on follow-up\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Is the Insured still on follow-up at your clinic?\")\n",
    "\n",
    "        # --- Terminal illness ---\n",
    "        elif \"Is the Insured terminally ill, ie death is expected within 12 months? If “Yes”, please provide details on the basis of your evaluation\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Terminal illness evaluation\")\n",
    "        elif \"the Insured terminally ill, ie death is expected within 12 months? If “Yes”, please indicate the date on which the Insured is assessed to be terminally ill\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Terminal illness assessment date (dd/mm/yyyy)\", name)\n",
    "        elif \"Is the Insured terminally ill, ie death is expected within 12 months?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Is the Insured terminally ill (i.e. death expected within 12 months)?\")\n",
    "\n",
    "        # --- Hospice ---\n",
    "        elif \"name of hospice\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Hospice name\")\n",
    "\n",
    "        elif \"Is the Insured referred to hospice care? If inpatient, please state date of admission\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Hospice inpatient admission date (dd/mm/yyyy)\", name)\n",
    "        elif \"Is the Insured referred to hospice care? If yes, please state if it is inpatient\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Hospice care type - Inpatient\")\n",
    "\n",
    "        elif \"Is the Insured referred to hospice care? If day care, please state start date (dd/mm/yyyy)\" in name:\n",
    "            set_date_with_confidence(field, combined, \"Hospice daycare start date (dd/mm/yyyy)\", name)\n",
    "        elif \"Is the Insured referred to hospice care? If yes, please state if it is day care\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Hospice care type - Day care\")\n",
    "\n",
    "\n",
    "        elif \"hospice care\" in name and (\"Yes\" in name or \"No\" in name):\n",
    "            set_checkbox_with_confidence(field, combined, \"Is the Insured referred to hospice care?\")\n",
    "\n",
    "        # --- Family / Medical / Lifestyle ---\n",
    "\n",
    "        elif \"Please give details of the Insured’s medical history which would have increased the risk of Cancer (including nature of illness, date of diagnosis and source of information)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical history that would have increased the risk of cancer\")\n",
    "        elif \"Please give details of the Insured’s family history which would have increased the risk of Cancer (including the relationship, nature of illness, date of  diagnosis and source of information)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family history that would have increased the risk of Cancer\")\n",
    "        elif \"Please give details of the Insured’s habits in relation to past and present smoking, including the duration of smoking habits, number of cigarettes smoked  per day and source of this information\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Smoking habits\")\n",
    "        elif \"Please give details of the Insured’s habits in relation to alcohol consumption, including the type of alcohol, amount of alcohol consumption per day,  duration of such consumption and source of this information\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Alcohol consumption habits\")\n",
    "\n",
    "        elif \"Is the tumour or cancer in any way caused directly or indirectly by alcohol or drug abuse?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Is the tumour or cancer in any way caused directly or indirectly by alcohol or drug abuse?\")\n",
    "\n",
    "\n",
    "        # --- HIV / AIDS ---\n",
    "        elif \"Is the tumour in the presence of Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)? If “Yes” please state HIV antibody status\" in name:\n",
    "            set_field_with_confidence(field, combined, \"HIV antibody status\")\n",
    "        elif \"Is the tumour in the presence of Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)? If “Yes” please state date of diagnosis for HIV/AIDS (dd/mm/yyyy)\" in name:\n",
    "            set_date_with_confidence(field, combined, \"HIV/AIDS diagnosis date (dd/mm/yyyy)\", name)\n",
    "        elif \"Is the tumour in the presence of Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Tumour caused by HIV or AIDS?\")\n",
    "\n",
    "\n",
    "        # --- Other significant health conditions ---\n",
    "\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of diagnosis (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (1) Diagnosis\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide name of doctor that diagnosed (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (1) Name of doctor\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of Name and address of clinic/ hospital (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (1) Name/address of clinic/hospital\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of date of diagnosis (dd/mm/yyyy) (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (1) Date of diagnosis (dd/mm/yyyy)\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of Duration of condition (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (1) Duration of condition\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of treatment received (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (1) Treatment received\")\n",
    "\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of diagnosis (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (2) Diagnosis\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide name of doctor that diagnosed (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (2) Name of doctor\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of Name and address of clinic/ hospital (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (2) Name/address of clinic/hospital\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of date of diagnosis (dd/mm/yyyy) (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (2) Date of diagnosis (dd/mm/yyyy)\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of Duration of condition (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (2) Duration of condition\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of treatment received (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (2) Treatment received\")\n",
    "\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of diagnosis (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (3) Diagnosis\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide name of doctor that diagnosed (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (3) Name of doctor\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of Name and address of clinic/ hospital (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (3) Name/address of clinic/hospital\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of date of diagnosis (dd/mm/yyyy) (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (3) Date of diagnosis (dd/mm/yyyy)\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of Duration of condition (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (3) Duration of condition\")\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)? If “Yes”, please provide details of treatment received (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of other health conditions (rows 0..3) (3) Treatment received\")\n",
    "\n",
    "        elif \"Does Insured have or ever had any other significant health condition(s)?\" in name:\n",
    "            set_checkbox_with_confidence(field, combined, \"Any other significant health conditions\")\n",
    "\n",
    "    return form_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSZG_Ok8OZF7"
   },
   "source": [
    "### MAPPER - GE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oi6XmMoOaPn"
   },
   "outputs": [],
   "source": [
    "def map_combined_to_fields_ge(combined, form_fields):\n",
    "    for field in form_fields[\"fields\"]:\n",
    "        name = field[\"field_name\"]\n",
    "\n",
    "        # --- Page 1 ---\n",
    "        if \"Date when insured first consulted you for cancer\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Date when insured first consulted you for cancer (ddmmyyyy)\")\n",
    "\n",
    "        elif \"Please state symptoms presented (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (1) Symptom\")\n",
    "        elif \"Please state duration of symptoms presented (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (1) Duration of symptom\")\n",
    "        elif \"Please state the date that the symptoms first appeared (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (1) Date symptoms first started (dd/mm/yyyy)\")\n",
    "\n",
    "        elif \"Please state symptoms presented (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (2) Symptom\")\n",
    "        elif \"Please state duration of symptoms presented (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (2) Duration of symptom\")\n",
    "        elif \"Please state the date that the symptoms first appeared (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (2) Date symptoms first started (dd/mm/yyyy)\")\n",
    "\n",
    "        elif \"Please state symptoms presented (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (3) Symptom\")\n",
    "        elif \"Please state duration of symptoms presented (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (3) Duration of symptom\")\n",
    "        elif \"Please state the date that the symptoms first appeared (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state symptoms presented and date symptoms first appeared (rows 0..3) (3) Date symptoms first started (dd/mm/yyyy)\")\n",
    "\n",
    "        elif \"What is the source of the above information? If \\\"Referring Doctor / Others\\\", please specify name (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"What is the source of the above information? If Referring Doctor / Others, specify name & address (rows 0..2) (1) Name\")\n",
    "        elif \"What is the source of the above information? If \\\"Referring Doctor / Others\\\", please specify address (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"What is the source of the above information? If Referring Doctor / Others, specify name & address (rows 0..2) (1) Address\")\n",
    "\n",
    "        elif \"What is the source of the above information? If \\\"Referring Doctor / Others\\\", please specify name (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"What is the source of the above information? If Referring Doctor / Others, specify name & address (rows 0..2) (2) Name\")\n",
    "        elif \"What is the source of the above information? If \\\"Referring Doctor / Others\\\", please specify address (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"What is the source of the above information? If Referring Doctor / Others, specify name & address (rows 0..2) (2) Address\")\n",
    "\n",
    "        elif \"What is the source of the above information?\" in name:\n",
    "            set_source_with_confidence(field, combined, \"Source of above information\")\n",
    "\n",
    "        elif \"Diagnosis was first made by (name of Doctor)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Diagnosis was first made by (name of Doctor)\")\n",
    "        elif \"Date when Cancer was FIRST diagnosed\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Date when Cancer was FIRST diagnosed (ddmmyyyy)\")\n",
    "\n",
    "        # --- Page 2 ---\n",
    "        elif \"Actual diagnosis\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Actual diagnosis\")\n",
    "        elif \"Date when insured first became aware of this illness (ddmmyyyy)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Date when insured first became aware of this illness (ddmmyyyy)\")\n",
    "\n",
    "        elif \"Was the illness suffered by Life Assured caused directly or indirectly by alcohol or drug abuse? If \\\"yes\\\", please give details\" in name:\n",
    "            set_field_with_confidence(field, combined, \"If illness caused directly or indirectly by alcohol or drug abuse, please give details\")\n",
    "        elif \"Was the illness suffered by Life Assured caused directly or indirectly by alcohol or drug abuse?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Was the illness suffered by Life Assured caused directly or indirectly by alcohol or drug abuse?\")\n",
    "\n",
    "        elif \"staging of the tumour\" in name:\n",
    "            set_field_with_confidence(field, combined, \"What is the staging of the tumour?\")\n",
    "        elif \"tumour classification\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please state the tumour classification (eg TMN classification etc)\")\n",
    "\n",
    "        elif \"Was the cancer completely localised?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Was the cancer completely localised?\")\n",
    "        elif \"Was there invasion of tissues?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Was there invasion of tissues?\")\n",
    "        elif \"Were regional lymph nodes involved?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Were regional lymph nodes involved?\")\n",
    "        elif \"Were there distant metastases?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Were there distant metastases?\")\n",
    "\n",
    "        elif \"Did the Life Assured undergo any surgery? If \\\"Yes\\\", please indicate the surgical procedure performed\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Surgical procedure performed\")\n",
    "        elif \"Did the Life Assured undergo any surgery? If \\\"Yes\\\", state the date of surgery (ddmmyyyy)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Date of surgery (ddmmyyyy)\")\n",
    "        elif \"Did the Life Assured undergo any surgery?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Did the Life Assured undergo any surgery?\")\n",
    "\n",
    "        elif \"Was there any other mode of treatment, other than surgery, which could be undertaken to treat the Life Assured's condition? If \\\"YES\\\", please specify type of treatment\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Type of treatment other than surgery that could be undertaken to treat condition\")\n",
    "        elif \"Was there any other mode of treatment, other than surgery, which could be undertaken to treat the Life Assured's condition?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Was there any other mode of treatment, other than surgery, which could be undertaken to treat the Life Assured’s condition?\")\n",
    "\n",
    "        # --- Page 3 ---\n",
    "        elif \"Has the Life Assured underwent other mode of treatment? If \\\"Yes\\\", please state date of treatment (ddmmyyyy)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Date of other treatment (ddmmyyyy)\")\n",
    "        elif \"Has the Life Assured underwent other mode of treatment? If \\\"No\\\", please state why not\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Reason for no other mode of treatment\")\n",
    "        elif \"Has the Life Assured underwent other mode of treatment?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Has the Life Assured undergone other mode of treatment?\")\n",
    "\n",
    "\n",
    "        elif \"What other forms of treatment did the Life Assured undergo\" in name:\n",
    "            set_field_with_confidence(field, combined, \"What other forms of treatment did the Life Assured undergo (eg chemotherapy, radiotherapy etc)?\")\n",
    "        elif \"If diagnosis is leukaemia\" in name:\n",
    "            set_field_with_confidence(field, combined, \"If diagnosis is leukaemia, please provide the type of leukaemia\")\n",
    "        elif \"malignant melanoma\" in name:\n",
    "            set_field_with_confidence(field, combined, \"If the diagnosis is malignant melanoma, please give full details of size, thickness (Breslow classification) and/or depth of invasion (Clark level)\")\n",
    "\n",
    "        elif \"Is the diagnosis related to Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)? If \\\"Yes\\\", please provide the date of diagnosis for HIV / AIDS (ddmmyyyy)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Date of diagnosis for HIV/AIDS (ddmmyyyy)\")\n",
    "        elif \"Is the diagnosis related to Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Is the diagnosis related to Human Immunodeficiency Virus (HIV) or Acquired Immune Deficiency Syndrome (AIDS)?\")\n",
    "\n",
    "        elif \"Please describe the Life Assured's mental and cognitive abilities\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Life Assured’s mental and cognitive abilities\")\n",
    "        elif \"Is the Life Assured mentally capable in accordance to the Mental Capacity Act (Chapter 177A of Singapore)? \" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Is Life Assured mentally capable?\")\n",
    "\n",
    "        # --- Page 4 ---\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state medical condition (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (1) Medical condition\")\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state date of diagnosis (dd/mm/yyyy) (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (1) Diagnosis date (dd/mm/yyyy)\")\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state name & address of treating doctor (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (1) Name & address of treating doctor\")\n",
    "\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state medical condition (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (2) Medical condition\")\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state date of diagnosis (dd/mm/yyyy) (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (2) Diagnosis date (dd/mm/yyyy)\")\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state name & address of treating doctor (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (2) Name & address of treating doctor\")\n",
    "\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state medical condition (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (3) Medical condition\")\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state date of diagnosis (dd/mm/yyyy) (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (3) Diagnosis date (dd/mm/yyyy)\")\n",
    "        elif \"Does the Life Assured have any other medical conditions? If \\\"YES\\\", please state name & address of treating doctor (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Medical conditions, date of diagnosis, name & address of treating doctor (rows 0..3) (3) Name & address of treating doctor\")\n",
    "\n",
    "        elif \"Does the Life Assured have any other medical conditions?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Does Life Assured have any other medical conditions?\")\n",
    "\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details of the nature of condition (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (1) Family history condition\")\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details including relationship to the Life Assured (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (1) Relationship to Life Assured\")\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details of the age of onset (1)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (1) Age of onset\")\n",
    "\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details of the nature of condition (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (2) Family history condition\")\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details including relationship to the Life Assured (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (2) Relationship to Life Assured\")\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details of the age of onset (2)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (2) Age of onset\")\n",
    "\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details of the nature of condition (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (3) Family history condition\")\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details including relationship to the Life Assured (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (3) Relationship to Life Assured\")\n",
    "        elif \"Does the Life Assured have any family history? If \\\"Yes\\\", please provide details of the age of onset (3)\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Family History (rows 0..3) (3) Age of onset\")\n",
    "\n",
    "        elif \"Does the Life Assured have any family history?\" in name:\n",
    "            set_delete_with_confidence(field, combined, \"Does Life Assured have any family history?\")\n",
    "\n",
    "        elif \"Please give details of the Life Assured's habits in relation to cigarette smoking, including the duration of smoking habit, number of cigarettes smoked per day and source of information\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of the Life Assured’s habits in relation to cigarette smoking, including the duration of smoking habit, number of cigarettes smoked per day and source of information\")\n",
    "\n",
    "        elif \"Please give details of the Life Assured's habit in relation to alcohol consumption including the amount of alcohol consumption per day and source of information\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Details of the Life Assured’s habit in relation to alcohol consumption including the amount of alcohol consumption per day and source of information\")\n",
    "\n",
    "        elif \"Please provide any other information which may be of assistance to us in assessing this claim\" in name:\n",
    "            set_field_with_confidence(field, combined, \"Please provide any other information which may be of assistance to us in assessing this claim\")\n",
    "\n",
    "        # --- Default for unmapped fields ---\n",
    "        else:\n",
    "            field[\"field_value\"] = \"\"\n",
    "            field[\"confidence\"] = \"\"\n",
    "\n",
    "    return form_fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g7UgTTDINIcq"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def process_llm_output(input_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Cleans an LLM output text file and converts it into a single flattened JSON file.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): raw LLM text.\n",
    "\n",
    "    Returns:\n",
    "        dict: The merged and flattened JSON object.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Helpers ---\n",
    "    def clean_llm_output(text: str) -> str:\n",
    "        text = re.sub(r\"--- Page \\d+ ---\", \"\", text)\n",
    "        text = re.sub(r\"```json\", \"\", text)\n",
    "        text = re.sub(r\"```\", \"\", text)\n",
    "\n",
    "        def _strip_comments(match):\n",
    "            s = match.group(0)\n",
    "            if s.startswith('\"'):\n",
    "                return s\n",
    "            return re.sub(r\"//.*\", \"\", s)\n",
    "\n",
    "        text = re.sub(r'\"(?:\\\\.|[^\"\\\\])*\"|[^\"\\n]+', _strip_comments, text)\n",
    "        text = re.sub(r\",\\s*([}\\]])\", r\"\\1\", text)\n",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "        text = re.sub(r\"\\n\\s*\\n\", \"\\n\", text)\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_json_objects(text: str):\n",
    "        objs = []\n",
    "        n = len(text)\n",
    "        i = 0\n",
    "        in_str = False\n",
    "        escape = False\n",
    "        depth = 0\n",
    "        start = None\n",
    "        while i < n:\n",
    "            ch = text[i]\n",
    "            if ch == '\"' and not escape:\n",
    "                in_str = not in_str\n",
    "            if not in_str:\n",
    "                if ch == '{':\n",
    "                    if depth == 0:\n",
    "                        start = i\n",
    "                    depth += 1\n",
    "                elif ch == '}':\n",
    "                    depth -= 1\n",
    "                    if depth == 0 and start is not None:\n",
    "                        objs.append(text[start:i+1])\n",
    "                        start = None\n",
    "            if ch == \"\\\\\" and not escape:\n",
    "                escape = True\n",
    "            else:\n",
    "                escape = False\n",
    "            i += 1\n",
    "        if start is not None:\n",
    "            tail = text[start:]\n",
    "            opens = tail.count('{') - tail.count('}')\n",
    "            opens_sq = tail.count('[') - tail.count(']')\n",
    "            tail_fixed = tail + ('}' * opens) + (']' * opens_sq)\n",
    "            objs.append(tail_fixed)\n",
    "        return objs\n",
    "\n",
    "    def repair_json(s: str) -> str:\n",
    "        s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
    "        open_curly = s.count('{') - s.count('}')\n",
    "        open_sq = s.count('[') - s.count(']')\n",
    "        if open_curly > 0:\n",
    "            s += '}' * open_curly\n",
    "        if open_sq > 0:\n",
    "            s += ']' * open_sq\n",
    "        return s\n",
    "\n",
    "    def flatten_json(obj: dict, parent_key: str = \"\", sep: str = \" \") -> dict:\n",
    "        items = {}\n",
    "        for k, v in obj.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\".strip()\n",
    "            if isinstance(v, dict):\n",
    "                items.update(flatten_json(v, new_key, sep=sep))\n",
    "            elif isinstance(v, list):\n",
    "                for idx, elem in enumerate(v, 1):\n",
    "                    if isinstance(elem, dict):\n",
    "                        items.update(flatten_json(elem, f\"{new_key} ({idx})\", sep=sep))\n",
    "                    else:\n",
    "                        items[f\"{new_key} ({idx})\"] = elem\n",
    "            else:\n",
    "                items[new_key] = v\n",
    "        return items\n",
    "\n",
    "    # --- Read + clean ---\n",
    "    cleaned = clean_llm_output(input_text)\n",
    "    json_chunks = extract_json_objects(cleaned)\n",
    "\n",
    "    merged = {}\n",
    "    all_keys = set()\n",
    "\n",
    "    for i, chunk in enumerate(json_chunks, 1):\n",
    "        fixed = repair_json(chunk)\n",
    "        try:\n",
    "            obj = json.loads(fixed)\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                first = fixed.find('{')\n",
    "                last = fixed.rfind('}')\n",
    "                if first != -1 and last != -1 and last > first:\n",
    "                    candidate = repair_json(fixed[first:last+1])\n",
    "                    obj = json.loads(candidate)\n",
    "                else:\n",
    "                    continue\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        flat = flatten_json(obj)\n",
    "        merged.update(flat)\n",
    "        all_keys.update(flat.keys())\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhu0bZwuaKYG"
   },
   "source": [
    "# Fill Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7w8ldx9CaL3r"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import fitz  # PyMuPDF library for PDF manipulation\n",
    "from typing import Dict, Tuple, Union, List\n",
    "import io\n",
    "\n",
    "# HELPER FUNCTION: Set checkbox/radio button state\n",
    "def _set_on_off(widget, should_check: bool) -> None:\n",
    "    \"\"\"\n",
    "    Sets the state of a checkbox or radio button widget.\n",
    "\n",
    "    Args:\n",
    "        widget: PyMuPDF widget object (checkbox or radio button)\n",
    "        should_check: Boolean indicating whether to check (True) or uncheck (False)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the widget's \"on\" and \"off\" state values (usually \"Yes\"/\"Off\")\n",
    "        on_val  = widget.on_state()  if hasattr(widget, \"on_state\")  else \"Yes\"\n",
    "        off_val = widget.off_state() if hasattr(widget, \"off_state\") else \"Off\"\n",
    "\n",
    "        # Set the appropriate value\n",
    "        widget.field_value = on_val if should_check else off_val\n",
    "        widget.update()  # Apply the change to the PDF\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] could not set widget '{widget.field_name}': {e}\")\n",
    "\n",
    "# HELPER FUNCTION: Auto-fit text to widget width\n",
    "def _fit_text_to_width(widget: fitz.Widget, value: str, max_fs: float = 11.0,\n",
    "                       min_fs: float = 6.0, pad: float = 2.0, fontname: str = \"Helv\") -> None:\n",
    "    \"\"\"\n",
    "    Dynamically adjusts font size to fit text within the widget's width.\n",
    "    Prevents text from being cut off in narrow fields.\n",
    "\n",
    "    Args:\n",
    "        widget: PyMuPDF text widget object\n",
    "        value: Text string to be inserted\n",
    "        max_fs: Maximum font size (default 11pt)\n",
    "        min_fs: Minimum font size (default 6pt)\n",
    "        pad: Padding on each side in points (default 2pt)\n",
    "        fontname: Font name - using \"Helv\" (Helvetica) to avoid font resource issues\n",
    "    \"\"\"\n",
    "    rect = fitz.Rect(widget.rect)\n",
    "    # Calculate available width (widget width minus padding on both sides)\n",
    "    avail = max(1.0, rect.width - 2 * pad)\n",
    "\n",
    "    # Find the longest line in the text (handles multi-line values)\n",
    "    lines = (value or \"\").splitlines() or [\"\"]\n",
    "    longest = max(lines, key=len)\n",
    "\n",
    "    # Measure how wide the text would be at max font size\n",
    "    width_at_max = fitz.get_text_length(longest, fontname=fontname, fontsize=max_fs)\n",
    "\n",
    "    # If text fits at max size, use max size; otherwise scale down proportionally\n",
    "    if width_at_max <= avail:\n",
    "        fs = max_fs\n",
    "    else:\n",
    "        fs = max(min_fs, (avail * max_fs) / max(1.0, width_at_max))\n",
    "\n",
    "    # Apply the calculated font size and value\n",
    "    widget.text_font = fontname\n",
    "    widget.text_fontsize = fs\n",
    "    widget.field_value = value\n",
    "    widget.update()  # Apply changes to the PDF\n",
    "\n",
    "# MAIN FUNCTION: Fill PDF form and return as bytes (Flask-ready)\n",
    "def fill_pdf_form(\n",
    "    pdf_source: Union[str, bytes],\n",
    "    form_data: Union[dict, str, List[dict]],\n",
    "    flatten: bool = False\n",
    ") -> bytes:\n",
    "    \"\"\"\n",
    "    Fills a PDF form with data and returns the filled PDF as bytes.\n",
    "    Perfect for Flask routes that serve PDFs directly.\n",
    "\n",
    "    Args:\n",
    "        pdf_source: Either a file path (str) or PDF bytes\n",
    "        form_data: Either:\n",
    "                   - A dict with \"fields\" key containing list of field dicts\n",
    "                   - A JSON string representing the same structure\n",
    "                   - A list of field dicts directly\n",
    "        flatten: If True, converts form fields to static content (non-editable)\n",
    "\n",
    "    Returns:\n",
    "        bytes: The filled PDF as bytes, ready to be sent via Flask\n",
    "\n",
    "    Example usage in Flask:\n",
    "        @app.route('/fill-form', methods=['POST'])\n",
    "        def fill_form():\n",
    "            pdf_bytes = fill_pdf_form(\n",
    "                pdf_source='template.pdf',\n",
    "                form_data=request.json,\n",
    "                flatten=False\n",
    "            )\n",
    "            return send_file(\n",
    "                io.BytesIO(pdf_bytes),\n",
    "                mimetype='application/pdf',\n",
    "                as_attachment=True,\n",
    "                download_name='filled_form.pdf'\n",
    "            )\n",
    "    \"\"\"\n",
    "\n",
    "    # STEP 1: Parse form data from various input formats\n",
    "    if isinstance(form_data, str):\n",
    "        # Parse JSON string\n",
    "        data = json.loads(form_data)\n",
    "        fields = data.get(\"fields\", [])\n",
    "    elif isinstance(form_data, list):\n",
    "        # Direct list of fields\n",
    "        fields = form_data\n",
    "    elif isinstance(form_data, dict):\n",
    "        # Dict with \"fields\" key or direct field mapping\n",
    "        fields = form_data.get(\"fields\", form_data if \"field_name\" in str(form_data) else [])\n",
    "    else:\n",
    "        raise ValueError(\"form_data must be dict, list, or JSON string\")\n",
    "\n",
    "    # STEP 2: Build lookup maps for efficient field matching\n",
    "    # Map (page_number, field_name) -> field_value for exact page+name matches\n",
    "    exact_map: Dict[Tuple[int, str], str] = {}\n",
    "    # Map field_name -> list of values (for fields appearing on multiple pages)\n",
    "    name_map: Dict[str, list] = {}\n",
    "\n",
    "    for it in fields:\n",
    "        page = int(it.get(\"page\", 0))\n",
    "        name = (it.get(\"field_name\") or \"\").strip()\n",
    "        val  = it.get(\"field_value\", \"\")\n",
    "\n",
    "        # Store in exact map if both page and name are available\n",
    "        if page and name:\n",
    "            exact_map[(page, name)] = val\n",
    "        # Store in name map for all fields with names\n",
    "        if name:\n",
    "            name_map.setdefault(name, []).append(val)\n",
    "\n",
    "    # STEP 3: Open the PDF document from file path or bytes\n",
    "    if isinstance(pdf_source, bytes):\n",
    "        doc = fitz.open(stream=pdf_source, filetype=\"pdf\")\n",
    "    else:\n",
    "        doc = fitz.open(pdf_source)\n",
    "\n",
    "    # STEP 4: Iterate through all pages and widgets (form fields)\n",
    "    for page in doc:\n",
    "        page_no = page.number + 1  # PyMuPDF uses 0-based indexing, convert to 1-based\n",
    "\n",
    "        # Get all form field widgets on this page\n",
    "        for w in (page.widgets() or []):\n",
    "            fname = (w.field_name or \"\").strip()\n",
    "            if not fname:\n",
    "                continue  # Skip widgets without names\n",
    "\n",
    "            # Find the value for this field\n",
    "            value = None\n",
    "\n",
    "            # First, try exact match (page + field name)\n",
    "            if (page_no, fname) in exact_map:\n",
    "                value = exact_map[(page_no, fname)]\n",
    "            else:\n",
    "                # If no exact match, try matching by name alone\n",
    "                # Only use this if the field name appears exactly once in the JSON\n",
    "                vals = name_map.get(fname)\n",
    "                if vals and len(vals) == 1:\n",
    "                    value = vals[0]\n",
    "\n",
    "            if value is None:\n",
    "                continue  # No value found for this field, skip it\n",
    "\n",
    "            # Fill the field based on its type\n",
    "            t = w.field_type\n",
    "            try:\n",
    "                # TEXT FIELD: Regular text input\n",
    "                if t == fitz.PDF_WIDGET_TYPE_TEXT:\n",
    "                    # Use auto-fit function to prevent text cutoff\n",
    "                    _fit_text_to_width(w, \"\" if value is None else str(value), max_fs=11.0, min_fs=6.0)\n",
    "\n",
    "                # CHECKBOX: On/off toggle\n",
    "                # LLM outputs \"Yes\" in field_value when the checkbox should be ticked\n",
    "                # Empty string or other values mean unchecked\n",
    "                elif t == fitz.PDF_WIDGET_TYPE_CHECKBOX:\n",
    "                    should_check = (str(value).strip().lower() == \"yes\")\n",
    "                    _set_on_off(w, should_check)\n",
    "\n",
    "                # RADIO BUTTON: Mutually exclusive options\n",
    "                # LLM outputs \"Yes\" in field_value when the radio button should be selected\n",
    "                elif t == fitz.PDF_WIDGET_TYPE_RADIOBUTTON:\n",
    "                    should_check = (str(value).strip().lower() == \"yes\")\n",
    "                    _set_on_off(w, should_check)\n",
    "\n",
    "                # COMBOBOX: Dropdown with optional text input\n",
    "                elif t == fitz.PDF_WIDGET_TYPE_COMBOBOX:\n",
    "                    choices = w.choice_values or []\n",
    "                    # Check if the combobox allows custom text entry\n",
    "                    is_editable_flag = getattr(fitz, \"PDF_CH_FIELD_IS_EDIT\", 1 << 18)\n",
    "                    is_editable = bool((w.field_flags or 0) & is_editable_flag)\n",
    "                    val_str = \"\" if value is None else str(value)\n",
    "\n",
    "                    # Only set value if it's in the choices OR the field is editable\n",
    "                    if is_editable or (choices and val_str in choices):\n",
    "                        w.field_value = val_str\n",
    "                        w.update()\n",
    "\n",
    "                # LISTBOX: Selection from a list\n",
    "                elif t == fitz.PDF_WIDGET_TYPE_LISTBOX:\n",
    "                    choices = w.choice_values or []\n",
    "                    val_str = \"\" if value is None else str(value)\n",
    "                    # Only set value if it exists in the available choices\n",
    "                    if choices and val_str in choices:\n",
    "                        w.field_value = val_str\n",
    "                        w.update()\n",
    "\n",
    "                # SIGNATURE: Digital signature field (skip filling)\n",
    "                elif t == fitz.PDF_WIDGET_TYPE_SIGNATURE:\n",
    "                    pass  # Signature fields require special handling\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[warn] failed to set '{fname}' on page {page_no}: {e}\")\n",
    "\n",
    "    # STEP 5: Optionally flatten the PDF (make fields non-editable)\n",
    "    if flatten:\n",
    "        if hasattr(doc, \"bake\"):\n",
    "            # \"Bake\" converts interactive fields to static content\n",
    "            doc.bake(widgets=True, annots=False)\n",
    "        else:\n",
    "            print(\"[info] Flatten skipped: your PyMuPDF version lacks Document.bake().\")\n",
    "\n",
    "    # STEP 6: Return the filled PDF as bytes\n",
    "    # Write PDF to a bytes buffer instead of file\n",
    "    pdf_bytes = doc.tobytes(deflate=True)\n",
    "    doc.close()\n",
    "\n",
    "    return pdf_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjkfCPNHY19V"
   },
   "source": [
    "# Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTRnzuMDY3E9"
   },
   "outputs": [],
   "source": [
    "import os, io, json, base64, threading, uuid, traceback\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from werkzeug.utils import secure_filename\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Flask App Setup + CORS\n",
    "app = Flask(__name__)\n",
    "CORS(app, supports_credentials=True, resources={\n",
    "    r\"/*\": {\n",
    "        \"origins\": [\"http://localhost:3000\", \"https://localhost:3000\", \"*\"],\n",
    "        \"allow_headers\": [\n",
    "            \"Content-Type\",\n",
    "            \"Authorization\",\n",
    "            \"ngrok-skip-browser-warning\",\n",
    "        ],\n",
    "        \"expose_headers\": [\"Content-Disposition\", \"Content-Type\"],\n",
    "        \"methods\": [\"GET\", \"POST\", \"OPTIONS\"],\n",
    "    }\n",
    "})\n",
    "\n",
    "BASE_DIR = \"/tmp/app\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "jobs = {}\n",
    "\n",
    "# Flask Utilities\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def write_json(data, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Helper Functions: Query Ollama LLM\n",
    "def query_ollama(prompt: str) -> str:\n",
    "    import requests\n",
    "    OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "    MODEL_NAME = \"phi4\"\n",
    "    payload = {\"model\": MODEL_NAME, \"prompt\": prompt}\n",
    "    output = \"\"\n",
    "    with requests.post(OLLAMA_URL, json=payload, stream=True) as r:\n",
    "        for line in r.iter_lines():\n",
    "            if line:\n",
    "                data = json.loads(line.decode(\"utf-8\"))\n",
    "                if \"response\" in data:\n",
    "                    output += data[\"response\"]\n",
    "    return output.strip()\n",
    "\n",
    "# Main Logic: run_llm_extraction_with_rag()\n",
    "def run_llm_extraction_with_rag(timeline: dict, insurer_type: str):\n",
    "    \"\"\"\n",
    "    RAG + LLM extraction using unified timeline from PDFUploadProcessor.\n",
    "    \"\"\"\n",
    "    import concurrent.futures\n",
    "\n",
    "    if not timeline:\n",
    "        print(\"Empty timeline — skipping RAG.\")\n",
    "        return {}\n",
    "\n",
    "    # STEP 1: Select insurer configuration\n",
    "    if insurer_type == \"NTUC\":\n",
    "        print(\"Running NTUC RAG retrieval ...\")\n",
    "        all_retrieval_results = retrieve_rag(timeline, ntuc_queries)\n",
    "        field_json_schemas = NTUC_FIELD_JSON_SCHEMAS\n",
    "    elif insurer_type == \"GE\":\n",
    "        print(\"Running GE RAG retrieval ...\")\n",
    "        all_retrieval_results = retrieve_rag(timeline, ge_queries)\n",
    "        field_json_schemas = GE_FIELD_JSON_SCHEMAS\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown insurer_type = {insurer_type}\")\n",
    "\n",
    "    # STEP 2: LLM per page / segment\n",
    "    def query_page(i, retrieved_text):\n",
    "        prompt = build_prompt(retrieved_text, i, field_json_schemas)\n",
    "        response = query_ollama(prompt)\n",
    "        return i, f\"\\n--- Page {i} ---\\n{response}\"\n",
    "\n",
    "    def run_all(all_retrieval_results, n_pages, field_json_schema, use_multithreading=True):\n",
    "        results = {}\n",
    "        if use_multithreading:\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=n_pages) as executor:\n",
    "                futures = []\n",
    "                for i in range(1, n_pages + 1):\n",
    "                    if i not in all_retrieval_results:\n",
    "                        continue\n",
    "                    text = all_retrieval_results[i].get(\"aggregated_text\", \"\")\n",
    "                    futures.append(executor.submit(query_page, i, text))\n",
    "                for f in concurrent.futures.as_completed(futures):\n",
    "                    i, output = f.result()\n",
    "                    results[i] = output\n",
    "        else:\n",
    "            for i in range(1, n_pages + 1):\n",
    "                if i not in all_retrieval_results:\n",
    "                    continue\n",
    "                text = all_retrieval_results[i].get(\"aggregated_text\", \"\")\n",
    "                i, output = query_page(i, text)\n",
    "                results[i] = output\n",
    "        return results\n",
    "\n",
    "    # Call it here\n",
    "    n_pages = min(len(all_retrieval_results.keys()), 5)\n",
    "    results = run_all(all_retrieval_results, n_pages, field_json_schemas, use_multithreading=True)\n",
    "\n",
    "    final_text = \"\\n\".join([results[i] for i in sorted(results.keys())])\n",
    "    combined_fields = process_llm_output(final_text)\n",
    "    return combined_fields\n",
    "\n",
    "# API ROUTES\n",
    "@app.route(\"/health\", methods=[\"GET\"])\n",
    "def health():\n",
    "    return jsonify({\"status\": \"ok\"}), 200\n",
    "\n",
    "\n",
    "@app.route(\"/ask\", methods=[\"POST\"])\n",
    "def ask():\n",
    "    job_id = str(uuid.uuid4())\n",
    "    job_dir = os.path.join(BASE_DIR, job_id)\n",
    "    os.makedirs(job_dir, exist_ok=True)\n",
    "\n",
    "    # accept multiple input PDFs\n",
    "    input_pdfs = request.files.getlist(\"input_pdfs\")\n",
    "    template_pdf = request.files.get(\"template_pdf\")\n",
    "    form_fields_json = request.files.get(\"form_fields_json\")\n",
    "\n",
    "    if not input_pdfs or not template_pdf or not form_fields_json:\n",
    "        return jsonify({\"error\": \"Missing one or more files\"}), 400\n",
    "\n",
    "    # save all PDF inputs\n",
    "    for f in input_pdfs:\n",
    "        save_path = os.path.join(job_dir, secure_filename(f.filename))\n",
    "        f.save(save_path)\n",
    "\n",
    "    template_path = os.path.join(job_dir, secure_filename(template_pdf.filename))\n",
    "    template_pdf.save(template_path)\n",
    "\n",
    "    json_path = os.path.join(job_dir, secure_filename(form_fields_json.filename))\n",
    "    form_fields_json.save(json_path)\n",
    "\n",
    "    # detect insurer\n",
    "    fname = template_pdf.filename.lower()\n",
    "    if \"income\" in fname:\n",
    "        insurer_type = \"NTUC\"\n",
    "    elif \"ge\" in fname or \"greateastern\" in fname:\n",
    "        insurer_type = \"GE\"\n",
    "    else:\n",
    "        insurer_type = \"UNKNOWN\"\n",
    "    print(f\"[{job_id}] Insurer detected: {insurer_type}\")\n",
    "\n",
    "    jobs[job_id] = {\"status\": \"pending\", \"result\": None, \"error\": None}\n",
    "\n",
    "    thread = threading.Thread(\n",
    "        target=process_pipeline,\n",
    "        args=(job_id, job_dir, template_path, json_path, job_dir, insurer_type),\n",
    "        daemon=True,\n",
    "    )\n",
    "    thread.start()\n",
    "    return jsonify({\"job_id\": job_id})\n",
    "\n",
    "\n",
    "@app.route(\"/result/<job_id>\", methods=[\"GET\"])\n",
    "def get_result(job_id):\n",
    "    job = jobs.get(job_id)\n",
    "    if not job:\n",
    "        return jsonify({\"error\": \"Job not found\"}), 404\n",
    "    if job[\"status\"] == \"completed\":\n",
    "        return jsonify({\n",
    "            \"status\": \"completed\",\n",
    "            \"pdf_b64\": job[\"result\"][\"pdf_b64\"],\n",
    "            \"form_fields_filled\": job[\"result\"][\"json\"],\n",
    "        })\n",
    "    elif job[\"status\"] == \"error\":\n",
    "        return jsonify({\"status\": \"error\", \"error\": job[\"error\"]})\n",
    "    else:\n",
    "        return jsonify({\"status\": \"pending\"})\n",
    "\n",
    "\n",
    "@app.route(\"/download/<job_id>\", methods=[\"GET\"])\n",
    "def download(job_id):\n",
    "    job_dir = os.path.join(BASE_DIR, job_id)\n",
    "    filled_path = os.path.join(job_dir, \"filled_template.pdf\")\n",
    "    if not os.path.exists(filled_path):\n",
    "        return jsonify({\"error\": \"PDF not found\"}), 404\n",
    "    return send_file(filled_path, as_attachment=True, download_name=f\"filled_{job_id}.pdf\")\n",
    "\n",
    "# PROCESSING PIPELINE \n",
    "def process_pipeline(job_id, input_dir, template_path, json_path, job_dir, insurer_type):\n",
    "    try:\n",
    "        print(f\"[{job_id}] Starting pipeline for {insurer_type}...\")\n",
    "\n",
    "        form_fields = read_json(json_path)\n",
    "\n",
    "        # STEP 1: OCR + Preprocessing (multi-file)\n",
    "        result = process_uploads(input_dir, run_ocr=True, multi=True)\n",
    "        timeline = result[\"timeline\"]\n",
    "        print(f\"[{job_id}] Pre-processing complete — Timeline ready with {len(timeline)} entries.\")\n",
    "\n",
    "        # stop if no extracted info\n",
    "        if not timeline or len(timeline) == 0:\n",
    "            raise ValueError(\"No extracted information. Please check the uploaded files.\")\n",
    "\n",
    "        # STEP 2: RAG + LLM extraction\n",
    "        combined_fields = run_llm_extraction_with_rag(timeline, insurer_type)\n",
    "        combined_path = os.path.join(job_dir, \"combined_fields.json\")\n",
    "        write_json(combined_fields, combined_path)\n",
    "        print(f\"[{job_id}] LLM extraction done. Fields: {len(combined_fields.keys())}\")\n",
    "\n",
    "        # STEP 3: Field mapping (insurer-specific)\n",
    "        if insurer_type == \"NTUC\":\n",
    "            filled_fields = map_combined_to_fields_income(combined_fields, form_fields)\n",
    "        elif insurer_type == \"GE\":\n",
    "            filled_fields = map_combined_to_fields_ge(combined_fields, form_fields)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported insurer form.\")\n",
    "\n",
    "        filled_json_path = os.path.join(job_dir, \"form_fields_filled.json\")\n",
    "        write_json(filled_fields, filled_json_path)\n",
    "        print(f\"[{job_id}] Mapping done.\")\n",
    "\n",
    "        # STEP 4: Fill PDF\n",
    "        filled_pdf_path = os.path.join(job_dir, \"filled_template.pdf\")\n",
    "        pdf_bytes = fill_pdf_form(template_path, filled_fields)\n",
    "        with open(filled_pdf_path, \"wb\") as f:\n",
    "            f.write(pdf_bytes)\n",
    "        print(f\"[{job_id}] PDF filled successfully.\")\n",
    "\n",
    "        # STEP 5: Encode final output\n",
    "        with open(filled_pdf_path, \"rb\") as f:\n",
    "            b64_pdf = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "        jobs[job_id] = {\n",
    "            \"status\": \"completed\",\n",
    "            \"result\": {\"pdf_b64\": b64_pdf, \"json\": filled_fields},\n",
    "            \"error\": None,\n",
    "        }\n",
    "        print(f\"[{job_id}] Completed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        jobs[job_id] = {\"status\": \"error\", \"error\": str(e)}\n",
    "        print(f\"[{job_id}] Error: {e}\")\n",
    "\n",
    "# Start Flask + ngrok\n",
    "def run_flask():\n",
    "    app.run(host=\"0.0.0.0\", port=5000, threaded=True)\n",
    "\n",
    "ngrok.set_auth_token(\"\") # fill with ngrok key\n",
    "public_tunnel = ngrok.connect(5000, \"http\")\n",
    "public_url = public_tunnel.public_url\n",
    "print(\"Public BASE_URL:\", public_url)\n",
    "\n",
    "threading.Thread(target=run_flask, daemon=True).start()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
