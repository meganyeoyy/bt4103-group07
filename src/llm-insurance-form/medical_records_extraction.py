import json
import re
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union

import fitz
import ocrmypdf


def scannedPdfConverter(
    file_path: Union[str, Path], save_path: Union[str, Path]
) -> None:
    """
    Convert a scanned PDF into a searchable/selectable PDF using OCR.

    Args:
        file_path (Union[str, Path]): Path to the scanned PDF file.
        save_path (Union[str, Path]): Path where the converted PDF should be saved.

    Returns:
        None
    """
    ocrmypdf.ocr(file_path, save_path, skip_text=True)
    print("File converted successfully!")


################################################
# Main Processing Pipeline
# -------------------------
# 1. Extract and clean PDF headers and footers
# -------------------------
def extract_text_no_header_footer(pdf_path: Union[str, Path]) -> str:
    """\
    Extracts text from a PDF while removing headers and footers.

    Args:
        pdf_path (Union[str, Path]): Path to the PDF file.

    Returns:
        str: Cleaned text from all pages of the PDF.
    """
    doc = fitz.open(pdf_path)
    pages: List[str] = []

    for page in doc:
        text = page.get_text("text")
        text = text.replace("#—! ", "")  # Remove extraction artifact

        # Regex removes hospital headers (2–3 lines)
        # Line 1: hospital name
        # Line 2: "Current Location: ..."
        text = re.sub(
            r"(?m)^\s*(?:National Cancer Centre|Singapore General Hospital|.*Hospital.*?)\s*\n"  # hospital name line
            r"^\s*Current Location:.*(?:\n\s*\S.*)?",  # location line (+ optional line 3)
            "",
            text,
        )

        # Regex removes footer lines "Requested by ... Page N of M ..."
        text = re.sub(r"(?im)^\s*Requested by:.*?Page\s*\d+\s*of\s*\d+.*$", "", text)

        pages.append(text.strip())

    return "\n\n".join(pages)


# -------------------------
# 2. Parse DMO sections & subsections (where applicable)
# -------------------------
def match_dmo_section_header(line: str) -> Optional[re.Match]:
    """
    Check if a line is a valid DMO section header.

    Args:
        line (str): Line of text to check.

    Returns:
        Optional[re.Match]: Regex match object if valid header, else None.

    Regex Explanation:
        ^DMO\s+ : Line starts with "DMO"
        (Consult|Correspondence|Pre-clerk Consult) : Section type
        \s+Note\s+(NCC|NCC-Memo) : Note type
        \s*\[Charted Location:.*?\] : Location in brackets
    """
    pattern = re.compile(
        r"^DMO\s+(Consult|Correspondence|Pre-clerk Consult)\s+Note\s+(NCC|NCC-Memo)\s*\[Charted Location:.*?\]",
        re.IGNORECASE,
    )
    return pattern.match(line.strip())


def is_dmo_section_header(line: str) -> bool:
    """
    Check if a line is a DMO section header.

    Args:
        line (str): Line of text to check.

    Returns:
        bool: True if line is a DMO header, else False.
    """
    return bool(match_dmo_section_header(line))


def is_ignored_section_header(line: str) -> bool:
    """
    Check if a line corresponds to an ignored section (e.g. Nursing/Pharmacy).

    Args:
        line (str): Line of text.

    Returns:
        bool: True if ignored section header, else False.
    """
    s = line.strip()
    return (
        s.upper().startswith("NUR")
        or s.upper().startswith("PHA")
        or s.upper().startswith("CTR")
        or s.upper().startswith("DISTRESS SCREENING NOTE")
    )


def is_last_updated_line(line: str) -> bool:
    """
    Check if a line starts with 'LAST UPDATED'.

    Args:
        line (str): Line of text.

    Returns:
        bool: True if 'Last Updated' line, else False.
    """
    return line.strip().upper().startswith("LAST UPDATED:")


def is_junk_line(line: str) -> bool:
    """
    Detect lines considered junk artifacts (separators, gibberish), generated by unicode extraction.

    Args:
        line (str): Line of text.

    Returns:
        bool: True if line is junk, else False.

    Regex Explanation:
        ([^\w\s])\1{8,} : Matches a non-alphanumeric, non-whitespace character
                          repeated at least 9 times in a row.
    """
    text = line.strip()
    if len(text) < 10:
        return False

    alnum = sum(1 for c in text if c.isalnum())
    ratio = alnum / max(1, len(text))

    if ratio < 0.25 or (len(text) > 30 and " " not in text and ratio < 0.5):
        return True

    if re.fullmatch(r"([^\w\s])\1{8,}", text):
        return True

    return False


def extract_dmo_sections(text: str) -> List[str]:
    """
    Extract DMO sections from text.

    Args:
        text (str): Input text.

    Returns:
        List[str]: List of extracted DMO sections.
    """
    lines = text.splitlines()
    sections: List[str] = []
    current: List[str] = []
    capturing = False

    for raw_line in lines:
        line = raw_line.rstrip("\n")
        if is_junk_line(line):
            continue
        if is_ignored_section_header(line):
            capturing = False
            current = []
            continue
        if is_dmo_section_header(line):
            if capturing and current:
                sections.append("\n".join(current))
            capturing = True
            current = [line]
            continue
        if capturing:
            current.append(line)
            if is_last_updated_line(line):
                sections.append("\n".join(current))
                current = []
                capturing = False

    if capturing and current:
        sections.append("\n".join(current))

    return sections


def split_into_subsections(text: str) -> Dict[str, str]:
    """
    Split section text into subsections based on predefined headers that may appear.

    Args:
        text (str): Section text.

    Returns:
        Dict[str, str]: Mapping of subsection header -> subsection content.

    Regex Explanation:
        (History, Examination...) : Matches known headers
        :? : Optional trailing colon
    """
    headers = [
        "History, Examination and Investigations",
        "Cancer Risk",
        "Investigations",
        "IMPRESSION",
        "Clinical and Treatment Summary",
        "DIAGNOSIS SUMMARY",
        "MANAGEMENT FOR THIS VISIT",
        "PATIENT STATUS",
    ]
    normalized_headers = {h.upper(): h for h in headers}
    pattern = "(" + "|".join([re.escape(h) + ":?" for h in headers]) + ")"

    parts = re.split(pattern, text, flags=re.IGNORECASE)
    subsections: Dict[str, str] = {}
    current_header = "General"
    buffer: List[str] = []

    for part in parts:
        candidate = part.strip().rstrip(":")
        if candidate.upper() in normalized_headers:
            if buffer:
                content = " ".join(buffer).strip()
                if content:
                    subsections[current_header] = content
                buffer = []
            current_header = normalized_headers[candidate.upper()]
        else:
            buffer.append(part)

    if buffer:
        content = " ".join(buffer).strip()
        if content:
            subsections[current_header] = content

    return {k: v for k, v in subsections.items() if v.strip()}


# -------------------------
# 3. Parse metadata
# -------------------------
# Compulsory metadata
def parse_dmo_metadata(section: str) -> Tuple[str, str, str]:
    """
    Parse compulsory metadata from a DMO section.

    Args:
        section (str): DMO section text.

    Returns:
        Tuple[str, str, str]: (authored_date, doctor, section_type)

    Regex Explanations:
        Authored:\s*(\d{1,2}-[A-Za-z]{3}-\d{4}) : Captures date dd-MMM-yyyy
        Last Updated:.*?by\s+([A-Za-z\s\-]+)\s*\(Doctor\) : Captures doctor name
    """
    authored_match = re.search(r"Authored:\s*(\d{1,2}-[A-Za-z]{3}-\d{4})", section)
    authored_date = authored_match.group(1) if authored_match else "UNKNOWN"

    doctor_match = re.search(
        r"Last Updated:.*?by\s+([A-Za-z\s\-]+)\s*\(Doctor\)", section
    )
    doctor = doctor_match.group(1).strip() if doctor_match else "UNKNOWN"

    header_match = match_dmo_section_header(section.splitlines()[0])
    section_type = header_match.group(1) if header_match else "UNKNOWN"

    return authored_date, doctor, section_type


# Additional metadata for enrichment (where applicable)
def extract_allergies(text: str) -> Optional[str]:
    """
    Extract allergies info from text.

    Args:
        text (str): Section text.

    Returns:
        Optional[str]: Allergies info or None if not found.

    Regex Explanation:
        Allergies[: ]+(.*) : Captures text following 'Allergies:'
    """
    if "No Known Allergies" in text or "nil known" in text.lower():
        return "NKA"
    if m := re.search(r"Allergies[: ]+(.*)", text):
        return m.group(1).strip()
    return None


def extract_family_history(text: str) -> Optional[str]:
    """
    Extract family history info from text.

    Args:
        text (str): Section text.

    Returns:
        Optional[str]: Family history info or None if not found.

    Regex Explanation:
        Family History.*?(?=History|CLINICAL|$) : Captures text until next header
    """
    if "Family History" not in text:
        return None
    fam_matches = re.findall(
        r"Family History.*?(?=History|CLINICAL|$)", text, re.IGNORECASE | re.DOTALL
    )
    return fam_matches[0].strip() if fam_matches else None


# --------------------------
# 4. Cleaning Extracted Text
# --------------------------
def month_abbr_to_num(abbr: str) -> str:
    """
    Convert a 3-letter month abbreviation to 2-digit number.

    Args:
        abbr (str): Month abbreviation.

    Returns:
        str: Two-digit month number.
    """
    months = {
        "Jan": "01",
        "Feb": "02",
        "Mar": "03",
        "Apr": "04",
        "May": "05",
        "Jun": "06",
        "Jul": "07",
        "Aug": "08",
        "Sep": "09",
        "Oct": "10",
        "Nov": "11",
        "Dec": "12",
    }
    return months.get(abbr, "01")


def normalize_formatting(text: str) -> str:
    """
    Normalize text formatting (dates, abbreviations).

    Args:
        text (str): Input text.

    Returns:
        str: Normalized text.

    Regex Explanations:
        (\d{1,2})-([A-Za-z]{3})-(\d{4}) : Captures dd-MMM-yyyy format
        [^\x00-\x7f]+ : Matches non-ASCII characters
    """
    text = re.sub(
        r"(\d{1,2})-([A-Za-z]{3})-(\d{4})",
        lambda m: f"{m.group(3)}-{month_abbr_to_num(m.group(2))}-{int(m.group(1)):02d}",
        text,
    )
    abbr_map = {
        "ANC": "Absolute Neutrophil Count",
        "URTI": "Upper Respiratory Tract Infection",
        "CRP": "C-Reactive Protein",
        "FBC": "Full Blood Count",
        "Hb": "Haemoglobin",
        "Plt": "Platelets",
        "Het": "Haematocrit",
        "PR": "progesterone receptor",
        "ER": "estrogen receptor",
        "Neoadjuvant": "pre-operative",
        "NAD": "no abnormality detected",
        "Hx:": "History:",
        "hx:": "History:",
        "O/E": "On examination:",
        "o/e ": "On examination:",
        "c/o": "complaints of",
        "s/b": "seen by",
        "Pt": "Patient",
    }
    for abbr, full in abbr_map.items():
        text = re.sub(rf"\b{abbr}\b", full, text)
    text = text.replace("\n", " ")
    text = re.sub(r"[^\x00-\x7F]+", "", text)
    return text


def remove_admin_noise(section_text: str) -> str:
    """
    Remove administrative lines (signatures, authored/last updated).

    Args:
        section_text (str): Section text.

    Returns:
        str: Cleaned text.

    Regex Explanations:
        ^\s*Electronic Signatures:.*$ : Removes signature lines
        ^\s*Authored:.*$ : Removes authored lines
        ^\s*[A-Za-z\s\.\-]+\(Doctor\)\s*\(Signed.*$ : Removes doctor signature lines
        ^\s*Last Updated:.*$ : Removes last updated line
    """
    text = re.sub(r"(?im)^\s*Electronic Signatures:.*$", "", section_text)
    text = re.sub(r"(?im)^\s*Authored:.*$", "", text)
    text = re.sub(r"(?im)^\s*[A-Za-z\s\.\-]+\(Doctor\)\s*\(Signed.*$", "", text)
    text = re.sub(r"(?im)^\s*Last Updated:.*$", "", text)
    text = re.sub(r"(?m)^\s*\|\s*", "", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()


def enrich_dmo_entry(
    section_dict: Dict[str, Union[str, Dict]],
) -> Dict[str, Union[str, List[str], Dict]]:
    """Enrich DMO entry with structured metadata.

    Args:
        section_dict (Dict[str, Union[str, Dict]]): Section data with doctor, type, text.

    Returns:
        Dict[str, Union[str, List[str], Dict]]: Enriched entry with subsections & allergies.
    """
    subsections = split_into_subsections(section_dict["text"])
    enriched = {
        **section_dict,
        "subsections": list(subsections.keys()),
        "allergies": extract_allergies(section_dict["text"]),
        "text": subsections,
    }
    return enriched


# -------------------------
# 4. Build timeline JSON
# -------------------------
def build_dmo_timeline(pdf_path: Union[str, Path]) -> Dict[str, List[Dict]]:
    """Build a timeline JSON from DMO sections in a PDF.

    Args:
        pdf_path (Union[str, Path]): Path to the PDF file.

    Returns:
        Dict[str, List[Dict]]: Timeline mapping authored date -> list of DMO entries.
    """
    raw_text = extract_text_no_header_footer(pdf_path)
    dmo_sections = extract_dmo_sections(raw_text)

    timeline: Dict[str, List[Dict]] = defaultdict(list)
    for sec in dmo_sections:
        date, doctor, section_type = parse_dmo_metadata(sec)
        sec_clean = remove_admin_noise(sec)
        sec_clean = normalize_formatting(sec_clean)
        entry = {"doctor": doctor, "section_type": section_type, "text": sec_clean}
        enriched = enrich_dmo_entry(entry)
        timeline[date].append(enriched)

    return dict(timeline)


if __name__ == "__main__":
    # TODO: Changes to be made based on where the files are stored after user upload; part of integration work
    # Example usage as below:
    scannedPdfConverter(r"../../data/SCM Records/Redacted - SCM_Patient 2.pdf", r"../../data/SCM Records/Converted/Redacted - SCM_Patient 2_Converted.pdf")

    pdf_path = f"../../data/SCM Records/Converted/Redacted - SCM_Patient 2_Converted.pdf"
    timeline = build_dmo_timeline(pdf_path)

    # print(json.dumps(timeline, indent=2))
    with open(
        f"../../data/SCM Records/Converted/Patient 2 Medical Records.json",
        "w",
        encoding="utf-8",
    ) as f:
        f.write(json.dumps(timeline, indent=2))
